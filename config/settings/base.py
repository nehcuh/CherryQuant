"""
CherryQuant åŸºç¡€é…ç½®è®¾ç½®
ä½¿ç”¨Pydanticè¿›è¡Œé…ç½®éªŒè¯å’Œç¯å¢ƒå˜é‡ç®¡ç†
"""

from pydantic import Field, ValidationInfo, field_validator, model_validator
from pydantic_settings import BaseSettings
from typing import Optional, List
import os
import logging
from dotenv import load_dotenv


# åœ¨å¯¼å…¥é…ç½®ç±»ä¹‹å‰ä¼˜å…ˆåŠ è½½é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ .envï¼Œ
# è¿™æ · pydantic-settings å¯ä»¥ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–åˆ°ç”¨æˆ·é…ç½®ã€‚
_ = load_dotenv()


# å…¼å®¹æ—§çš„ç¯å¢ƒå˜é‡å‘½åï¼š
# - DATA_MODE -> MODEï¼ˆä¾› DataSourceConfig.mode ä½¿ç”¨ï¼‰
# - DATA_SOURCE -> SOURCEï¼ˆä¾› DataSourceConfig.source ä½¿ç”¨ï¼‰ï¼Œå¹¶ç§»é™¤ DATA_SOURCEï¼Œ
#   é¿å…è¢« CherryQuantConfig.data_source è§†ä¸ºæ•´ä½“ JSON é…ç½®ã€‚
if os.getenv("DATA_MODE") and not os.getenv("MODE"):
    os.environ["MODE"] = os.environ["DATA_MODE"]

if os.getenv("DATA_SOURCE"):
    if not os.getenv("SOURCE"):
        os.environ["SOURCE"] = os.environ["DATA_SOURCE"]
    # é¿å…åµŒå¥— BaseSettings å°† DATA_SOURCE å½“æˆå¤æ‚å¯¹è±¡æ¥è§£æ
    _ = os.environ.pop("DATA_SOURCE", None)

# å…¼å®¹ AI ç¯å¢ƒå˜é‡å‘½åï¼šå°† OPENAI_* æ˜ å°„åˆ°é€šç”¨å­—æ®µï¼Œ
# ä»¥ä¾¿ AIConfig(model/base_url/api_key) èƒ½åœ¨ pydantic-settings v2 ä¸‹æ­£å¸¸è¯»å–ã€‚
if os.getenv("OPENAI_MODEL") and not os.getenv("MODEL"):
    os.environ["MODEL"] = os.environ["OPENAI_MODEL"]

if os.getenv("OPENAI_BASE_URL") and not os.getenv("BASE_URL"):
    os.environ["BASE_URL"] = os.environ["OPENAI_BASE_URL"]

if os.getenv("OPENAI_API_KEY") and not os.getenv("API_KEY"):
    os.environ["API_KEY"] = os.environ["OPENAI_API_KEY"]

logger = logging.getLogger(__name__)


class DatabaseConfig(BaseSettings):
    """æ•°æ®åº“é…ç½®"""

    # MongoDB é…ç½®
    mongodb_uri: str = Field(
        default="mongodb://localhost:27017",
        description="MongoDBè¿æ¥URI",
    )
    mongodb_database: str = Field(default="cherryquant", description="MongoDBæ•°æ®åº“å")
    mongodb_min_pool_size: int = Field(default=5, description="MongoDBæœ€å°è¿æ¥æ± å¤§å°")
    mongodb_max_pool_size: int = Field(default=50, description="MongoDBæœ€å¤§è¿æ¥æ± å¤§å°")
    mongodb_username: str | None = Field(default=None, description="MongoDBç”¨æˆ·å")
    mongodb_password: str | None = Field(default=None, description="MongoDBå¯†ç ")

    # Redis é…ç½®ï¼ˆç”¨äºç¼“å­˜ï¼‰
    redis_host: str = Field(default="localhost")
    redis_port: int = Field(default=6379)
    redis_db: int = Field(default=0, description="Redisæ•°æ®åº“ç¼–å·")
    redis_password: str | None = Field(default=None, description="Rediså¯†ç ")

    cache_ttl: int = Field(default=300, description="ç¼“å­˜TTLï¼ˆç§’ï¼‰")

    @field_validator("mongodb_uri")
    def validate_mongodb_uri(cls, v: str):
        """éªŒè¯MongoDB URI"""
        if not v.startswith("mongodb://") and not v.startswith("mongodb+srv://"):
            raise ValueError(
                "MongoDB URI must start with 'mongodb://' or 'mongodb+srv://'"
            )
        return v

    class Config:
        env_file: str = ".env"
        env_file_encoding: str = "utf-8"
        case_sensitive: bool = True
        extra: str = "ignore"


class AIConfig(BaseSettings):
    """AIé…ç½®

    æ³¨æ„ï¼šæ­¤é…ç½®é€šè¿‡ env_file/.env ä¸ç¯å¢ƒå˜é‡æ˜ å°„ï¼Œç”¨äºé©±åŠ¨
    AsyncOpenAIClientï¼Œè€Œä¸å†åœ¨é€‚é…å±‚ä¸­ç›´æ¥è¯»å– os.environã€‚
    """

    model: str = Field(
        default="gpt-4o", description="ä½¿ç”¨çš„AIæ¨¡å‹", alias="OPENAI_MODEL"
    )
    base_url: str = Field(
        default="https://api.openai.com/v1",
        description="APIåŸºç¡€URL",
        alias="OPENAI_BASE_URL",
    )
    api_key: str = Field(default="", description="APIå¯†é’¥", alias="OPENAI_API_KEY")
    temperature: float = Field(
        default=0.3, description="AIæ¸©åº¦å‚æ•°", alias="OPENAI_TEMPERATURE"
    )
    max_retries: int = Field(
        default=3, description="æœ€å¤§é‡è¯•æ¬¡æ•°", alias="OPENAI_MAX_RETRIES"
    )
    timeout: int = Field(
        default=30, description="APIè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰", alias="OPENAI_TIMEOUT"
    )

    class Config:
        """ç¯å¢ƒå˜é‡ä¸ .env åŠ è½½é…ç½®ï¼ˆå…¼å®¹ç°æœ‰ OPENAI_* / *_TIMEOUT ç­‰å˜é‡ï¼‰"""

        env_file: str = ".env"
        env_file_encoding: str = "utf-8"
        extra: str = "ignore"

    @field_validator("api_key")
    def validate_api_key(cls, v: str, info: ValidationInfo):
        """éªŒè¯APIå¯†é’¥"""
        # è·å–base_urlé…ç½®
        base_url = str(info.data.get("base_url", ""))  # type: ignore[arg-type]

        # å¦‚æœbase_urlåŒ…å«æœ¬åœ°åœ°å€ï¼Œåˆ™å¿½ç•¥APIå¯†é’¥éªŒè¯
        local_indicators = ["localhost", "127.0.0.1", "0.0.0.0", "::1"]
        if any(indicator in base_url for indicator in local_indicators):
            logger.info("â„¹ï¸  ä½¿ç”¨æœ¬åœ°APIæœåŠ¡ï¼Œè·³è¿‡APIå¯†é’¥éªŒè¯")
            return v

        if not v or v == "your_openai_api_key_here":
            logger.warning("âš ï¸ OpenAI APIå¯†é’¥æœªé…ç½®ï¼ŒAIåŠŸèƒ½å°†æ— æ³•ä½¿ç”¨")
        return v

    @field_validator("temperature")
    def validate_temperature(cls, v: float):
        """éªŒè¯æ¸©åº¦å‚æ•°"""
        if not 0 <= v <= 2:
            raise ValueError("AI temperatureå¿…é¡»åœ¨0-2ä¹‹é—´")
        return v


class TradingConfig(BaseSettings):
    """äº¤æ˜“é…ç½®"""

    default_symbol: str = Field(default="rb2601", description="é»˜è®¤äº¤æ˜“åˆçº¦")
    exchange: str = Field(default="SHFE", description="é»˜è®¤äº¤æ˜“æ‰€")
    decision_interval: int = Field(default=300, description="å†³ç­–é—´éš”ï¼ˆç§’ï¼‰")
    max_position_size: int = Field(default=10, description="æœ€å¤§æŒä»“æ‰‹æ•°")
    default_leverage: float = Field(default=5.0, description="é»˜è®¤æ æ†")
    risk_per_trade: float = Field(default=0.02, description="æ¯ç¬”äº¤æ˜“é£é™©æ¯”ä¾‹")

    @field_validator("default_leverage")
    def validate_leverage(cls, v: float):
        if not 1 <= v <= 10:
            raise ValueError("leverage must be between 1 and 10")
        return v


class DataSourceConfig(BaseSettings):
    """æ•°æ®æºé…ç½®

    è¯´æ˜ï¼š
    - æ¨èä½¿ç”¨ .env ä¸­çš„ DATA_MODEã€DATA_SOURCEï¼Œ
      æˆ‘ä»¬åœ¨æ¨¡å—å¯¼å…¥æ—¶å·²å°†å…¶æ˜ å°„ä¸º MODE / SOURCE ä¾›æœ¬é…ç½®ä½¿ç”¨ã€‚
    """

    mode: str = Field(
        default="dev",
        description="æ•°æ®æ¨¡å¼: live(CTPå®æ—¶) | dev(Tushare å‡†å®æ—¶)",
        alias="DATA_MODE",
    )
    source: str = Field(
        default="tushare", description="æ•°æ®æºç±»å‹", alias="DATA_SOURCE"
    )
    tushare_token: Optional[str] = Field(default=None, description="Tushareä»¤ç‰Œ")

    # CTPé…ç½®
    ctp_userid: str | None = Field(default=None, description="CTPç”¨æˆ·ID")
    ctp_password: str | None = Field(default=None, description="CTPå¯†ç ")
    ctp_broker_id: str = Field(default="9999", description="CTPæœŸè´§å…¬å¸ID")
    ctp_md_address: str = Field(
        default="tcp://180.168.146.187:10131",
        description="CTPè¡Œæƒ…æœåŠ¡å™¨",
    )
    ctp_td_address: str = Field(
        default="tcp://180.168.146.187:10130",
        description="CTPäº¤æ˜“æœåŠ¡å™¨",
    )

    @field_validator("data_mode")
    def validate_mode(cls, v: str):
        """éªŒè¯æ•°æ®æ¨¡å¼"""
        if v not in ("live", "dev"):
            raise ValueError("DATA_MODE must be 'live' or 'dev'")
        return v

    @field_validator("tushare_token")
    def validate_tushare_token(cls, v: str):
        """éªŒè¯Tushareä»¤ç‰Œ"""
        if not v or v == "your_tushare_pro_token_here":
            logger.warning("âš ï¸ Tushare Pro Tokenæœªé…ç½®ï¼Œä¸»åŠ›åˆçº¦è§£æå’Œå†å²æ•°æ®åŠŸèƒ½å—é™")
        return v

    @model_validator(mode="after")
    def validate_live_mode_requirements(self):
        """éªŒè¯liveæ¨¡å¼çš„å¿…éœ€é…ç½®"""
        data_mode = self.data_mode
        if data_mode == "live":
            # éªŒè¯ CTP é…ç½®
            if not self.ctp_userid:
                raise ValueError("liveæ¨¡å¼éœ€è¦é…ç½®CTP_USERID")
            if not self.ctp_password:
                raise ValueError("liveæ¨¡å¼éœ€è¦é…ç½®CTP_PASSWORD")

            logger.info("âœ… liveæ¨¡å¼é…ç½®éªŒè¯é€šè¿‡")
        else:
            logger.info(f"â„¹ï¸  ä½¿ç”¨ {data_mode} æ¨¡å¼ï¼ˆå¼€å‘/æµ‹è¯•æ¨¡å¼ï¼‰")

        return self


class RiskConfig(BaseSettings):
    """ç»„åˆé£é™©ç®¡ç†é…ç½®"""

    max_total_capital_usage: float = Field(default=0.8, description="æœ€å¤§æ€»èµ„é‡‘ä½¿ç”¨ç‡")
    max_correlation_threshold: float = Field(default=0.7, description="æœ€å¤§ç›¸å…³æ€§é˜ˆå€¼")
    max_sector_concentration: float = Field(
        default=0.4,
        description="æœ€å¤§å•ä¸€æ¿å—é›†ä¸­åº¦",
    )
    portfolio_stop_loss: float = Field(default=0.1, description="ç»„åˆæ­¢æŸæ¯”ä¾‹")
    daily_loss_limit: float = Field(default=0.05, description="æ¯æ—¥äºæŸé™åˆ¶")
    max_leverage_total: float = Field(default=3.0, description="æ€»æ æ†é™åˆ¶")

    @field_validator(
        "max_total_capital_usage",
        "max_correlation_threshold",
        "max_sector_concentration",
    )
    @classmethod
    def validate_percentage(cls, v: float):
        """éªŒè¯ç™¾åˆ†æ¯”å‚æ•°"""
        if not 0 < v <= 1:
            raise ValueError(f"Value must be between 0 and 1, got {v}")
        return v

    @field_validator("portfolio_stop_loss", "daily_loss_limit")
    @classmethod
    def validate_loss_limit(cls, v: float):
        """éªŒè¯æ­¢æŸå‚æ•°"""
        if not 0 < v <= 0.5:
            raise ValueError(f"Loss limit must be between 0 and 0.5, got {v}")
        return v

    @field_validator("max_leverage_total")
    @classmethod
    def validate_leverage(cls, v: float):
        """éªŒè¯æ æ†å‚æ•°"""
        if not 1 <= v <= 10:
            raise ValueError("max_leverage_total must be between 1 and 10")
        return v


class LoggingConfig(BaseSettings):
    """æ—¥å¿—é…ç½®"""

    level: str = Field(default="INFO", description="æ—¥å¿—çº§åˆ«")
    log_dir: str = Field(default="./logs", description="æ—¥å¿—ç›®å½•")
    max_bytes: int = Field(default=10485760, description="å•ä¸ªæ—¥å¿—æ–‡ä»¶æœ€å¤§å­—èŠ‚æ•°")
    backup_count: int = Field(default=5, description="ä¿ç•™æ—¥å¿—æ–‡ä»¶æ•°é‡")

    # Structured logging configuration
    json_logs: bool = Field(
        default=False,
        description="Enable JSON structured logs for production",
        alias="LOG_JSON",
    )
    enable_colors: bool = Field(
        default=True,
        description="Enable colored console output (disabled for JSON logs)",
        alias="LOG_COLORS",
    )


class AlertsConfig(BaseSettings):
    """è­¦æŠ¥/é€šçŸ¥é…ç½®

    é€šè¿‡ç¯å¢ƒå˜é‡æˆ– .env æ–‡ä»¶ç»Ÿä¸€ç®¡ç†é‚®ä»¶ã€å¾®ä¿¡ã€é’‰é’‰å’Œé€šç”¨ Webhook é€šçŸ¥ã€‚
    """

    # é‚®ä»¶é…ç½®
    smtp_server: str = Field(
        default="smtp.gmail.com",
        description="SMTP æœåŠ¡",
    )
    smtp_port: int = Field(
        default=587,
        description="SMTP ç«¯å£",
    )
    email_sender: str = Field(
        default="cherryquant@example.com",
        description="å‘ä»¶äººé‚®ç®±",
    )
    email_username: str = Field(
        default="cherryquant@example.com",
        description="ç™»å½•ç”¨æˆ·å",
    )
    email_password: str = Field(
        default="",
        description="é‚®ç®±å¯†ç /æˆæƒç ",
    )
    email_recipients: list[str] = Field(
        default_factory=lambda: ["admin@example.com"],
        description="æ”¶ä»¶äººåˆ—è¡¨",
    )

    # å¾®ä¿¡é…ç½®
    wechat_webhook_url: str = Field(
        default="",
        description="ä¼ä¸šå¾®ä¿¡ Webhook URL",
    )
    wechat_enabled: bool = Field(
        default=False,
        description="æ˜¯å¦å¯ç”¨å¾®ä¿¡é€šçŸ¥",
    )

    # é’‰é’‰é…ç½®
    dingtalk_webhook_url: str = Field(
        default="",
        description="é’‰é’‰ Webhook URL",
    )
    dingtalk_enabled: bool = Field(
        default=False,
        description="æ˜¯å¦å¯ç”¨é’‰é’‰é€šçŸ¥",
    )

    # é€šç”¨ Webhook é…ç½®
    alert_webhook_url: str = Field(
        default="",
        description="é€šç”¨å‘Šè­¦ Webhook åœ°å€",
    )
    webhook_token: str = Field(
        default="",
        description="Webhook è®¤è¯ Token",
    )

    @field_validator("email_recipients", mode="before")
    @classmethod
    def split_recipients(cls, v: str):  # type: ignore[override]
        """æ”¯æŒé€—å·åˆ†éš”å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ä¸¤ç§å½¢å¼"""
        return [item.strip() for item in v.split(",") if item.strip()]

    class Config:
        env_file: str = ".env"
        env_file_encoding: str = "utf-8"
        extra: str = "ignore"


class CherryQuantConfig(BaseSettings):
    """CherryQuantä¸»é…ç½®"""

    database: DatabaseConfig = DatabaseConfig()
    ai: AIConfig = AIConfig()
    trading: TradingConfig = TradingConfig()
    data_source: DataSourceConfig = DataSourceConfig()
    risk: RiskConfig = RiskConfig()
    logging: LoggingConfig = LoggingConfig()
    alerts: AlertsConfig = AlertsConfig()

    # ç¯å¢ƒé…ç½®
    environment: str = Field(default="development", description="è¿è¡Œç¯å¢ƒ")
    debug: bool = Field(default=False, description="è°ƒè¯•æ¨¡å¼")
    timezone: str = Field(default="Asia/Shanghai", description="æ—¶åŒº")

    @classmethod
    def from_env(cls) -> "CherryQuantConfig":
        """ä»ç¯å¢ƒå˜é‡åˆ›å»ºé…ç½®"""
        try:
            config = cls()
            logger.info("âœ… é…ç½®åŠ è½½æˆåŠŸ")
            return config
        except Exception as e:
            logger.error(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {e}")
            raise

    def print_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ CherryQuant é…ç½®æ‘˜è¦")
        print("=" * 60)
        print(f"ğŸŒ è¿è¡Œç¯å¢ƒ: {self.environment}")
        print(f"ğŸ› è°ƒè¯•æ¨¡å¼: {self.debug}")
        print(f"ğŸ• æ—¶åŒº: {self.timezone}")
        print(f"\nğŸ“Š æ•°æ®æ¨¡å¼: {self.data_source.mode}")
        print(f"ğŸ“¡ æ•°æ®æº: {self.data_source.source}")
        print(f"ğŸ¤– AIæ¨¡å‹: {self.ai.model}")
        print(
            f"ğŸ’¾ MongoDB: {self.database.mongodb_uri}/{self.database.mongodb_database}"
        )
        print(
            f"ğŸ—ƒï¸  Redisç¼“å­˜: {self.database.redis_host}:{self.database.redis_port}/{self.database.redis_db}"
        )
        print(f"ğŸ“ æ—¥å¿—çº§åˆ«: {self.logging.level}")
        print(f"ğŸ“ æ—¥å¿—ç›®å½•: {self.logging.log_dir}")

        print(f"\nğŸ›¡ï¸  é£é™©ç®¡ç†é…ç½®:")
        print(f"  - æœ€å¤§èµ„é‡‘ä½¿ç”¨ç‡: {self.risk.max_total_capital_usage:.0%}")
        print(f"  - ç»„åˆæ­¢æŸ: {self.risk.portfolio_stop_loss:.0%}")
        print(f"  - æ¯æ—¥äºæŸé™åˆ¶: {self.risk.daily_loss_limit:.0%}")
        print(f"  - æœ€å¤§æ¿å—é›†ä¸­åº¦: {self.risk.max_sector_concentration:.0%}")
        print(f"  - æœ€å¤§æ€»æ æ†: {self.risk.max_leverage_total:.1f}x")

        if self.data_source.mode == "live":
            print(f"\nğŸ”´ LIVE æ¨¡å¼é…ç½®:")
            print(f"  - CTPè´¦æˆ·: {self.data_source.ctp_userid}")
            print(f"  - CTP Broker: {self.data_source.ctp_broker_id}")
            print(f"  - è¡Œæƒ…æœåŠ¡å™¨: {self.data_source.ctp_md_address}")
            print(f"  - äº¤æ˜“æœåŠ¡å™¨: {self.data_source.ctp_td_address}")
        else:
            print(f"\nğŸŸ¢ DEV æ¨¡å¼é…ç½®:")
            print(f"  - ä½¿ç”¨å‡†å®æ—¶æ•°æ®ï¼ˆAKShareï¼‰")
            print(f"  - æ— éœ€CTPè´¦æˆ·")

        print("=" * 60 + "\n")

    def validate_for_production(self):
        """ç”Ÿäº§ç¯å¢ƒé…ç½®éªŒè¯"""
        issues: list[str] = []

        if self.environment == "production":
            # ç”Ÿäº§ç¯å¢ƒå¿…é¡»æ£€æŸ¥
            # if not self.database.mongodb_username or not self.database.mongodb_password:
            #     issues.append("âš ï¸ ç”Ÿäº§ç¯å¢ƒåº”å¯ç”¨MongoDBè®¤è¯")

            # if not self.ai.api_key or self.ai.api_key == "your_openai_api_key_here":
            #     issues.append("âš ï¸ OpenAI APIå¯†é’¥æœªé…ç½®")

            if self.data_source.mode == "live":
                if not self.data_source.ctp_userid or not self.data_source.ctp_password:
                    issues.append("âš ï¸ CTPè´¦æˆ·é…ç½®ä¸å®Œæ•´")

        if issues:
            logger.warning("ç”Ÿäº§ç¯å¢ƒé…ç½®æ£€æŸ¥å‘ç°é—®é¢˜:")
            for issue in issues:
                logger.warning(f"  {issue}")
            return False

        logger.info("âœ… ç”Ÿäº§ç¯å¢ƒé…ç½®æ£€æŸ¥é€šè¿‡")
        return True


# å…¨å±€é…ç½®å®ä¾‹
CONFIG = CherryQuantConfig.from_env()

# æ‰“å°é…ç½®æ‘˜è¦ï¼ˆä»…åœ¨ç›´æ¥è¿è¡Œæ—¶ï¼‰
if __name__ == "__main__":
    CONFIG.print_summary()
    if CONFIG.validate_for_production():
        print("Ready for production")
    else:
        print("Not ready")
