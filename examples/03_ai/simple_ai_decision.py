#!/usr/bin/env python3
"""
ç®€å•AIå†³ç­–ç¤ºä¾‹

éš¾åº¦ï¼šâ­â­ åˆçº§

å­¦ä¹ è¦ç‚¹ï¼š
1. OpenAI API è°ƒç”¨
2. åŸºæœ¬æç¤ºè¯è®¾è®¡
3. JSON è¾“å‡ºè§£æ
4. é”™è¯¯å¤„ç†

è¿è¡Œæ–¹å¼ï¼š
    uv run python examples/03_ai/simple_ai_decision.py

å‰ç½®è¦æ±‚ï¼š
    - è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡
    - è®¾ç½® OPENAI_BASE_URLï¼ˆå¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
"""

import asyncio
import json
import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from cherryquant.ai.llm_client.openai_client import LLMClient


async def example_1_basic_decision():
    """ç¤ºä¾‹1ï¼šåŸºç¡€AIå†³ç­–"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1: åŸºç¡€AIäº¤æ˜“å†³ç­–")
    print("=" * 60 + "\n")

    # 1. æ£€æŸ¥APIé…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key.startswith("sk-xxx"):
        print("âŒ é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("   è·å–æ–¹å¼: https://platform.openai.com")
        return

    # 2. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
    print("ğŸ¤– åˆå§‹åŒ– AI å®¢æˆ·ç«¯...")
    client = LLMClient(
        api_key=api_key,
        base_url=os.getenv("OPENAI_BASE_URL"),
        model=os.getenv("OPENAI_MODEL", "gpt-4-turbo-preview"),
    )
    print(f"âœ… ä½¿ç”¨æ¨¡å‹: {client.model}\n")

    # 3. æ„é€ å¸‚åœºæ•°æ®
    market_context = """
å“ç§: èºçº¹é’¢ (rb2501)
æ¿å—: é»‘è‰²é‡‘å±

å½“å‰è¡Œæƒ…:
- æœ€æ–°ä»·: Â¥3,520
- æ¶¨è·Œå¹…: +1.8%
- æˆäº¤é‡: è¾ƒæ˜¨æ—¥æ”¾å¤§30%

æŠ€æœ¯æŒ‡æ ‡:
- MA5: 3,480 (ä»·æ ¼åœ¨MA5ä¹‹ä¸Š)
- MA20: 3,450 (ä»·æ ¼çªç ´MA20)
- RSI: 68 (ç•¥å¾®è¶…ä¹°ï¼Œä½†æœªè¾¾æå€¼)
- MACD: é‡‘å‰å½¢æˆï¼ŒæŸ±çŠ¶å›¾è½¬æ­£

å¸‚åœºæƒ…ç»ª:
- é’¢å‚å¼€å·¥ç‡ç¨³å®š
- ä¸‹æ¸¸éœ€æ±‚å­£èŠ‚æ€§å›æš–
- åº“å­˜æ°´å¹³å¤„äºä¸­ç­‰åä½
"""

    # 4. å®šä¹‰æç¤ºè¯
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æœŸè´§äº¤æ˜“åˆ†æå¸ˆã€‚

ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„å¸‚åœºæ•°æ®å’ŒæŠ€æœ¯æŒ‡æ ‡ï¼Œç»™å‡ºæ˜ç¡®çš„äº¤æ˜“å»ºè®®ã€‚

è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼JSONï¼‰:
{
    "action": "BUY" | "SELL" | "HOLD",
    "confidence": 0.0-1.0,
    "reasoning": "è¯¦ç»†çš„åˆ†æç†ç”±",
    "risk_level": "LOW" | "MEDIUM" | "HIGH"
}"""

    user_prompt = f"""è¯·åˆ†æä»¥ä¸‹å¸‚åœºæ•°æ®å¹¶ç»™å‡ºäº¤æ˜“å»ºè®®ï¼š

{market_context}

è¯·è¾“å‡ºJSONæ ¼å¼çš„å†³ç­–ã€‚"""

    # 5. è°ƒç”¨AI
    print("ğŸ§  æ­£åœ¨è¯·æ±‚AIå†³ç­–...\n")

    try:
        decision = await client.get_trading_decision_async(
            system_prompt=system_prompt, user_prompt=user_prompt
        )

        if decision:
            print("âœ… AIå†³ç­–ç»“æœ:")
            print(f"   åŠ¨ä½œ: {decision.get('action', 'N/A')}")
            print(f"   ç½®ä¿¡åº¦: {decision.get('confidence', 0):.1%}")
            print(f"   é£é™©ç­‰çº§: {decision.get('risk_level', 'N/A')}")
            print(f"   ç†ç”±: {decision.get('reasoning', 'N/A')[:200]}...")
        else:
            print("âš ï¸  AIè¿”å›ç©ºå†³ç­–")

    except Exception as e:
        print(f"âŒ AIè°ƒç”¨å¤±è´¥: {e}")

    print("\nâœ… ç¤ºä¾‹1å®Œæˆ")


async def example_2_multi_scenarios():
    """ç¤ºä¾‹2ï¼šå¤šåœºæ™¯å†³ç­–å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2: å¤šåœºæ™¯å†³ç­–å¯¹æ¯”")
    print("=" * 60 + "\n")

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key.startswith("sk-xxx"):
        print("âŒ è¯·è®¾ç½® OPENAI_API_KEY")
        return

    client = LLMClient(api_key=api_key)

    # å®šä¹‰3ä¸ªä¸åŒçš„å¸‚åœºåœºæ™¯
    scenarios = [
        {
            "name": "å¼ºåŠ¿ä¸Šæ¶¨",
            "context": "ä»·æ ¼: Â¥3,600 (+3.5%), RSI: 75, MACDå¼ºé‡‘å‰, æˆäº¤é‡æš´å¢",
        },
        {
            "name": "å¼±åŠ¿éœ‡è¡",
            "context": "ä»·æ ¼: Â¥3,480 (-0.5%), RSI: 48, MACDæ­»å‰, æˆäº¤é‡èç¼©",
        },
        {
            "name": "æš´è·Œåå¼¹",
            "context": "ä»·æ ¼: Â¥3,350 (-5%), RSI: 28, MACDåº•èƒŒç¦», ææ…Œæ€§æŠ›å”®åä¼ç¨³",
        },
    ]

    system_prompt = """ä½ æ˜¯æœŸè´§åˆ†æå¸ˆã€‚åŸºäºå¸‚åœºæ•°æ®ç»™å‡ºJSONæ ¼å¼çš„äº¤æ˜“å»ºè®®ï¼š
{"action": "BUY/SELL/HOLD", "confidence": 0-1, "reasoning": "ç†ç”±"}"""

    print("ğŸ§  æµ‹è¯•3ä¸ªä¸åŒåœºæ™¯çš„AIå†³ç­–...\n")

    for scenario in scenarios:
        print(f"  åœºæ™¯: {scenario['name']}")
        print(f"  æ•°æ®: {scenario['context']}")

        try:
            decision = await client.get_trading_decision_async(
                system_prompt=system_prompt,
                user_prompt=f"åˆ†æ: {scenario['context']}",
            )

            if decision:
                print(
                    f"  â†’ å†³ç­–: {decision.get('action')} "
                    f"(ç½®ä¿¡åº¦: {decision.get('confidence', 0):.0%})"
                )
            print()

        except Exception as e:
            print(f"  â†’ é”™è¯¯: {e}\n")

        await asyncio.sleep(1)  # é¿å…APIé™æµ

    print("âœ… ç¤ºä¾‹2å®Œæˆ")


async def example_3_temperature_comparison():
    """ç¤ºä¾‹3ï¼šæ¸©åº¦å‚æ•°å¯¹æ¯”"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 3: Temperatureå‚æ•°å¯¹å†³ç­–ä¸€è‡´æ€§çš„å½±å“")
    print("=" * 60 + "\n")

    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key or api_key.startswith("sk-xxx"):
        print("âŒ è¯·è®¾ç½® OPENAI_API_KEY")
        return

    print("ğŸ’¡ ç›¸åŒè¾“å…¥ï¼Œæµ‹è¯•ä¸åŒtemperatureå‚æ•°ï¼ˆ3æ¬¡é‡‡æ ·ï¼‰\n")

    market_data = "rb2501: ä»·æ ¼Â¥3,500 (+1%), RSI:65, MA5>MA20, æˆäº¤é‡æ­£å¸¸"

    temperatures = [0.1, 0.7, 1.5]

    for temp in temperatures:
        print(f"  Temperature = {temp}:")

        client = LLMClient(api_key=api_key, temperature=temp)

        for i in range(3):
            try:
                decision = await client.get_trading_decision_async(
                    system_prompt="ä½ æ˜¯æœŸè´§åˆ†æå¸ˆï¼Œè¾“å‡ºJSON: {\"action\": \"BUY/SELL/HOLD\"}",
                    user_prompt=f"åˆ†æ: {market_data}",
                )

                action = decision.get("action", "N/A") if decision else "ERROR"
                print(f"    ç¬¬{i+1}æ¬¡: {action}")

            except Exception as e:
                print(f"    ç¬¬{i+1}æ¬¡: é”™è¯¯ - {e}")

            await asyncio.sleep(0.5)

        print()

    print("ğŸ’¡ è§‚å¯Ÿ: Temperatureè¶Šä½ï¼Œå†³ç­–è¶Šä¸€è‡´ï¼›è¶Šé«˜ï¼Œå†³ç­–è¶Šéšæœº")
    print("âœ… ç¤ºä¾‹3å®Œæˆ")


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "=" * 70)
    print("ğŸ“š CherryQuant AIå†³ç­–ç¤ºä¾‹ - ç®€å•AIå†³ç­–")
    print("=" * 70)

    try:
        await example_1_basic_decision()
        await example_2_multi_scenarios()
        await example_3_temperature_comparison()

        print("\n" + "=" * 70)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("=" * 70)
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥:")
        print("  1. è¿è¡Œ examples/03_ai/prompt_engineering.py å­¦ä¹ æç¤ºè¯ä¼˜åŒ–")
        print("  2. é˜…è¯» docs/adr/0003-prompt-engineering-ai.md")
        print("  3. å®Œæˆ Lab 03 å®éªŒä»»åŠ¡")
        print()

    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ é”™è¯¯: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
