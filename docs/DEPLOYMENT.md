# CherryQuant ç”Ÿäº§éƒ¨ç½²æŒ‡å—

**ç‰ˆæœ¬**: v0.5-beta
**æ›´æ–°æ—¥æœŸ**: 2024å¹´
**çŠ¶æ€**: Production Ready âœ…

---

## ğŸ“‹ ç›®å½•

- [ç¯å¢ƒè¦æ±‚](#ç¯å¢ƒè¦æ±‚)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [è¯¦ç»†é…ç½®](#è¯¦ç»†é…ç½®)
- [æ•°æ®åº“è®¾ç½®](#æ•°æ®åº“è®¾ç½®)
- [è¿è¡Œå’Œç›‘æ§](#è¿è¡Œå’Œç›‘æ§)
- [æ€§èƒ½è°ƒä¼˜](#æ€§èƒ½è°ƒä¼˜)
- [æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)
- [å®‰å…¨å»ºè®®](#å®‰å…¨å»ºè®®)

---

## ğŸ”§ ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|---------|---------|
| **OS** | Linux/macOS | Ubuntu 20.04+ / CentOS 8+ |
| **Python** | 3.7+ | 3.10+ |
| **MongoDB** | 4.4+ | 5.0+ (æ”¯æŒæ—¶é—´åºåˆ—) |
| **Redis** (å¯é€‰) | 6.0+ | 7.0+ |
| **å†…å­˜** | 2GB | 8GB+ |
| **å­˜å‚¨** | 10GB | 100GB+ SSD |
| **CPU** | 2æ ¸ | 4æ ¸+ |

### Pythonä¾èµ–

```bash
# æ ¸å¿ƒä¾èµ–
python >= 3.7
motor >= 3.0  # MongoDBå¼‚æ­¥é©±åŠ¨
pymongo >= 4.0
redis >= 4.0  # å¯é€‰ï¼šç”¨äºL2ç¼“å­˜
aioredis >= 2.0  # å¯é€‰ï¼šå¼‚æ­¥Redis

# æ•°æ®é‡‡é›†ä¾èµ–
tushare >= 1.2  # Tushareæ•°æ®æº
pandas >= 1.3
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/your-org/CherryQuant.git
cd CherryQuant
```

### 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# æˆ–
.venv\Scripts\activate  # Windows
```

### 3. å®‰è£…ä¾èµ–

```bash
pip install -e .

# æˆ–ä½¿ç”¨requirements.txt
pip install -r requirements.txt
```

### 4. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env`ï¼š

```ini
# MongoDB é…ç½®
MONGODB_URI=mongodb://localhost:27017
MONGODB_DATABASE=cherryquant_prod

# Redis é…ç½® (å¯é€‰)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=

# Tushare API
TUSHARE_TOKEN=your_token_here

# åº”ç”¨é…ç½®
APP_ENV=production
LOG_LEVEL=INFO
```

### 5. å¯åŠ¨MongoDB

```bash
# Dockeræ–¹å¼ï¼ˆæ¨èï¼‰
docker run -d \
  --name mongodb \
  -p 27017:27017 \
  -v mongodb_data:/data/db \
  -e MONGO_INITDB_ROOT_USERNAME=admin \
  -e MONGO_INITDB_ROOT_PASSWORD=your_password \
  mongo:5.0

# æˆ–ä½¿ç”¨docker-compose
docker-compose up -d mongodb
```

### 6. åˆå§‹åŒ–æ•°æ®åº“

```python
from cherryquant.data import DataPipeline
import asyncio

async def init_database():
    pipeline = DataPipeline()
    await pipeline.initialize()
    print("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

asyncio.run(init_database())
```

### 7. éªŒè¯å®‰è£…

```bash
# è¿è¡Œæµ‹è¯•
pytest tests/integration/ -v

# æ£€æŸ¥æ•°æ®ç®¡é“
python -c "
from cherryquant.data import DataPipeline
print('âœ… å¯¼å…¥æˆåŠŸ')
"
```

---

## âš™ï¸ è¯¦ç»†é…ç½®

### ç¯å¢ƒå˜é‡è¯´æ˜

#### MongoDB é…ç½®

```ini
# åŸºç¡€è¿æ¥
MONGODB_URI=mongodb://user:pass@host:port/?authSource=admin
MONGODB_DATABASE=cherryquant_prod

# è¿æ¥æ± é…ç½®
MONGODB_MAX_POOL_SIZE=100  # æœ€å¤§è¿æ¥æ•°
MONGODB_MIN_POOL_SIZE=10   # æœ€å°è¿æ¥æ•°
MONGODB_TIMEOUT=30000      # è¿æ¥è¶…æ—¶ï¼ˆæ¯«ç§’ï¼‰
```

#### Redis é…ç½®ï¼ˆL2ç¼“å­˜ï¼‰

```ini
# åŸºç¡€é…ç½®
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your_redis_password
REDIS_DB=0

# ç¼“å­˜é…ç½®
CACHE_L1_SIZE=1000          # L1å†…å­˜ç¼“å­˜å¤§å°
CACHE_L1_TTL=300            # L1ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
CACHE_L2_TTL=3600           # L2ç¼“å­˜è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
```

#### Tushare APIé…ç½®

```ini
# APIè®¤è¯
TUSHARE_TOKEN=your_token_here

# é€Ÿç‡é™åˆ¶
TUSHARE_RATE_LIMIT=100      # æ¯åˆ†é’Ÿæœ€å¤§è°ƒç”¨æ¬¡æ•°
```

#### é‡è¯•å’Œå®¹é”™é…ç½®

```ini
# é‡è¯•é…ç½®
RETRY_MAX_ATTEMPTS=3        # æœ€å¤§é‡è¯•æ¬¡æ•°
RETRY_BASE_DELAY=1.0        # åŸºç¡€å»¶è¿Ÿï¼ˆç§’ï¼‰
RETRY_MAX_DELAY=60.0        # æœ€å¤§å»¶è¿Ÿï¼ˆç§’ï¼‰

# æ–­è·¯å™¨é…ç½®
CIRCUIT_FAILURE_THRESHOLD=5      # å¤±è´¥é˜ˆå€¼
CIRCUIT_SUCCESS_THRESHOLD=2      # æˆåŠŸé˜ˆå€¼
CIRCUIT_TIMEOUT=60.0             # æ–­è·¯å™¨è¶…æ—¶ï¼ˆç§’ï¼‰
```

---

## ğŸ’¾ æ•°æ®åº“è®¾ç½®

### MongoDB æ—¶é—´åºåˆ—é›†åˆ

CherryQuant ä½¿ç”¨ MongoDB æ—¶é—´åºåˆ—é›†åˆå­˜å‚¨å¸‚åœºæ•°æ®ï¼Œæ€§èƒ½ä¼˜å¼‚ã€‚

#### åˆ›å»ºæ—¶é—´åºåˆ—é›†åˆ

```javascript
// åœ¨MongoDB shellä¸­æ‰§è¡Œ
use cherryquant_prod;

// åˆ›å»º1åˆ†é’ŸKçº¿é›†åˆ
db.createCollection("market_data_1m", {
  timeseries: {
    timeField: "datetime",
    metaField: "metadata",
    granularity: "minutes"
  }
});

// åˆ›å»ºæ—¥çº¿é›†åˆ
db.createCollection("market_data_1d", {
  timeseries: {
    timeField: "datetime",
    metaField: "metadata",
    granularity: "hours"
  }
});

// åˆ›å»ºç´¢å¼•
db.market_data_1d.createIndex(
  { "metadata.symbol": 1, "datetime": 1 },
  { name: "symbol_time_idx" }
);
```

#### è‡ªåŠ¨åˆå§‹åŒ–ï¼ˆæ¨èï¼‰

ä½¿ç”¨Pythonè‡ªåŠ¨åˆ›å»ºï¼š

```python
from cherryquant.data.storage.timeseries_repository import TimeSeriesRepository
from cherryquant.data.collectors.base_collector import TimeFrame
import asyncio

async def setup_database():
    repo = TimeSeriesRepository(connection_manager)

    # ä¸ºæ‰€æœ‰æ—¶é—´å‘¨æœŸåˆ›å»ºç´¢å¼•
    for timeframe in TimeFrame:
        await repo.ensure_indexes(timeframe)
        print(f"âœ… ç´¢å¼•åˆ›å»ºå®Œæˆ: {timeframe.value}")

asyncio.run(setup_database())
```

### MongoDB æ€§èƒ½ä¼˜åŒ–

#### 1. ç´¢å¼•ä¼˜åŒ–

```javascript
// å¤åˆç´¢å¼•ï¼ˆæŸ¥è¯¢ä¼˜åŒ–ï¼‰
db.market_data_1d.createIndex(
  {
    "metadata.exchange": 1,
    "metadata.symbol": 1,
    "datetime": 1
  },
  { background: true }
);

// æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
db.market_data_1d.aggregate([
  { $indexStats: {} }
]);
```

#### 2. è¿æ¥æ± é…ç½®

```python
from cherryquant.adapters.data_storage.mongodb_manager import MongoDBConnectionManager

manager = MongoDBConnectionManager(
    uri="mongodb://localhost:27017",
    database="cherryquant_prod",
    max_pool_size=100,  # æ ¹æ®å¹¶å‘é‡è°ƒæ•´
    min_pool_size=10,
    max_idle_time_ms=60000,
)
```

#### 3. å†™å…¥æ€§èƒ½ä¼˜åŒ–

```python
# ä½¿ç”¨æ‰¹é‡æ’å…¥
from cherryquant.data.storage.timeseries_repository import TimeSeriesRepository

repo = TimeSeriesRepository(manager)

# æ‰¹é‡ä¿å­˜ï¼ˆæ€§èƒ½æå‡10-100å€ï¼‰
await repo.save_batch(
    market_data_list,
    ordered=False  # å…è®¸éƒ¨åˆ†å¤±è´¥ï¼Œç»§ç»­æ’å…¥
)
```

---

## ğŸ”„ è¿è¡Œå’Œç›‘æ§

### åŸºç¡€ä½¿ç”¨ç¤ºä¾‹

#### 1. æ•°æ®é‡‡é›†

```python
from cherryquant.data import DataPipeline, TushareCollector, Exchange, TimeFrame
from datetime import datetime, timedelta
import asyncio

async def collect_data():
    # åˆå§‹åŒ–ç®¡é“
    pipeline = DataPipeline()
    await pipeline.initialize()

    # é‡‡é›†æ•°æ®
    result = await pipeline.collect_and_save(
        symbols=["rb2501", "hc2501"],
        exchange=Exchange.SHFE,
        start_date=datetime.now() - timedelta(days=30),
        end_date=datetime.now(),
        timeframe=TimeFrame.DAY_1,
    )

    print(f"âœ… é‡‡é›†å®Œæˆ: {result['total_saved']} æ¡æ•°æ®")

asyncio.run(collect_data())
```

#### 2. æ•°æ®æŸ¥è¯¢

```python
from cherryquant.data import QueryBuilder
import asyncio

async def query_data():
    builder = QueryBuilder(timeseries_repo)

    # æ„å»ºæŸ¥è¯¢
    data = await (builder
        .symbol("rb2501")
        .exchange(Exchange.SHFE)
        .date_range(
            datetime(2024, 1, 1),
            datetime(2024, 1, 31)
        )
        .timeframe(TimeFrame.DAY_1)
        .execute()
    )

    print(f"ğŸ“Š æŸ¥è¯¢ç»“æœ: {len(data)} æ¡")
    return data

asyncio.run(query_data())
```

### å®šæ—¶ä»»åŠ¡è®¾ç½®

#### ä½¿ç”¨ cron å®šæ—¶é‡‡é›†

åˆ›å»º `scripts/daily_collect.py`:

```python
#!/usr/bin/env python
"""æ¯æ—¥æ•°æ®é‡‡é›†è„šæœ¬"""
import asyncio
from datetime import datetime, timedelta
from cherryquant.data import DataPipeline, Exchange, TimeFrame

async def main():
    pipeline = DataPipeline()
    await pipeline.initialize()

    # é‡‡é›†æ˜¨æ—¥æ•°æ®
    yesterday = datetime.now() - timedelta(days=1)

    result = await pipeline.collect_and_save(
        symbols=["rb", "hc", "cu"],  # ä¸»åŠ›åˆçº¦
        exchange=Exchange.SHFE,
        start_date=yesterday,
        end_date=yesterday,
        timeframe=TimeFrame.DAY_1,
    )

    print(f"âœ… æ—¥çº¿é‡‡é›†å®Œæˆ: {result}")

if __name__ == "__main__":
    asyncio.run(main())
```

é…ç½® crontab:

```bash
# ç¼–è¾‘crontab
crontab -e

# æ¯å¤©16:00æ‰§è¡Œæ•°æ®é‡‡é›†
0 16 * * 1-5 cd /path/to/CherryQuant && /path/to/.venv/bin/python scripts/daily_collect.py >> logs/collect.log 2>&1
```

### æ—¥å¿—é…ç½®

åˆ›å»º `logging_config.py`:

```python
import logging.config

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'detailed': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        },
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'level': 'INFO',
            'formatter': 'detailed',
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'filename': 'logs/cherryquant.log',
            'maxBytes': 10485760,  # 10MB
            'backupCount': 5,
            'formatter': 'detailed',
            'level': 'DEBUG',
        },
    },
    'root': {
        'level': 'INFO',
        'handlers': ['console', 'file'],
    },
}

logging.config.dictConfig(LOGGING_CONFIG)
```

### ç›‘æ§æŒ‡æ ‡

#### å…³é”®æŒ‡æ ‡

1. **æ•°æ®é‡‡é›†æŒ‡æ ‡**
   - é‡‡é›†æˆåŠŸç‡
   - é‡‡é›†å»¶è¿Ÿ
   - APIè°ƒç”¨æ¬¡æ•°
   - é‡è¯•æ¬¡æ•°

2. **æ•°æ®åº“æŒ‡æ ‡**
   - å†™å…¥QPS
   - æŸ¥è¯¢å»¶è¿Ÿ
   - è¿æ¥æ± ä½¿ç”¨ç‡
   - æ…¢æŸ¥è¯¢æ—¥å¿—

3. **ç¼“å­˜æŒ‡æ ‡**
   - L1å‘½ä¸­ç‡
   - L2å‘½ä¸­ç‡
   - ç¼“å­˜å¤§å°
   - æ·˜æ±°æ¬¡æ•°

#### ç›‘æ§è„šæœ¬ç¤ºä¾‹

```python
from cherryquant.data import DataPipeline
import asyncio

async def monitor_stats():
    pipeline = DataPipeline()

    # è·å–ç¼“å­˜ç»Ÿè®¡
    cache_stats = pipeline.cache_strategy.stats
    print(f"L1 å‘½ä¸­ç‡: {cache_stats['l1_hits'] / (cache_stats['l1_hits'] + cache_stats['l1_misses']):.2%}")

    # è·å–æ•°æ®åº“ç»Ÿè®¡
    # (éœ€è¦ä»MongoDBè·å–)

asyncio.run(monitor_stats())
```

---

## âš¡ æ€§èƒ½è°ƒä¼˜

### 1. æ‰¹é‡æ“ä½œä¼˜åŒ–

```python
# âŒ ä¸æ¨èï¼šé€æ¡æ’å…¥
for data in data_list:
    await repo.save(data)

# âœ… æ¨èï¼šæ‰¹é‡æ’å…¥
await repo.save_batch(data_list)  # æ€§èƒ½æå‡10-100å€
```

### 2. ç¼“å­˜ç­–ç•¥

```python
from cherryquant.data.storage.cache_strategy import CacheStrategy

# é…ç½®ä¸‰çº§ç¼“å­˜
cache = CacheStrategy(
    enable_l1=True,
    enable_l2=True,
    l1_max_size=1000,     # æ ¹æ®å†…å­˜è°ƒæ•´
    l1_ttl=300,           # 5åˆ†é’Ÿ
    l2_ttl=3600,          # 1å°æ—¶
    redis_client=redis_client,
)
```

### 3. è¿æ¥å¤ç”¨

```python
# âœ… ä½¿ç”¨è¿æ¥æ± ï¼Œè‡ªåŠ¨ç®¡ç†
from cherryquant.adapters.data_storage.mongodb_manager import MongoDBConnectionManager

manager = MongoDBConnectionManager(
    uri="mongodb://localhost:27017",
    database="cherryquant_prod",
    max_pool_size=100,
)

# å¤ç”¨åŒä¸€ä¸ªmanagerå®ä¾‹
repo1 = TimeSeriesRepository(manager)
repo2 = MetadataRepository(manager)
```

### 4. å¹¶å‘æ§åˆ¶

```python
import asyncio
from cherryquant.data import BatchQueryExecutor

# æ‰¹é‡å¹¶å‘æŸ¥è¯¢
executor = BatchQueryExecutor(repo, max_concurrent=10)

requests = [
    {"symbol": f"rb250{i}", "exchange": Exchange.SHFE, ...}
    for i in range(12)
]

results = await executor.execute_batch(requests)
```

---

## ğŸ› æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

#### 1. MongoDB è¿æ¥å¤±è´¥

**é”™è¯¯**: `pymongo.errors.ServerSelectionTimeoutError`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥MongoDBæ˜¯å¦è¿è¡Œ
docker ps | grep mongodb

# æ£€æŸ¥è¿æ¥å­—ç¬¦ä¸²
ping <mongodb_host>

# æ£€æŸ¥è®¤è¯
mongo --host <host> --username <user> --password <pass>

# æ£€æŸ¥é˜²ç«å¢™
telnet <host> 27017
```

#### 2. Tushare API é™æµ

**é”™è¯¯**: `æŠ±æ­‰ï¼Œæ‚¨æ¯åˆ†é’Ÿæœ€å¤šè®¿é—®è¯¥æ¥å£100æ¬¡`

**è§£å†³æ–¹æ¡ˆ**:
```python
# è°ƒæ•´é€Ÿç‡é™åˆ¶
collector = TushareCollector(
    token="your_token",
    call_limit_per_minute=50  # é™ä½è°ƒç”¨é¢‘ç‡
)

# æˆ–ä½¿ç”¨é‡è¯•æœºåˆ¶ï¼ˆå·²å†…ç½®ï¼‰
# ç³»ç»Ÿä¼šè‡ªåŠ¨é‡è¯•
```

#### 3. å†…å­˜ä¸è¶³

**ç—‡çŠ¶**: ç¨‹åºå´©æºƒæˆ–OOMé”™è¯¯

**è§£å†³æ–¹æ¡ˆ**:
```python
# å‡å°ç¼“å­˜å¤§å°
cache = CacheStrategy(
    l1_max_size=500,  # ä»1000é™è‡³500
)

# åˆ†æ‰¹å¤„ç†
BATCH_SIZE = 1000
for i in range(0, len(data_list), BATCH_SIZE):
    batch = data_list[i:i+BATCH_SIZE]
    await repo.save_batch(batch)
```

#### 4. æŸ¥è¯¢æ…¢

**è¯Šæ–­**:
```javascript
// MongoDBæ…¢æŸ¥è¯¢æ—¥å¿—
db.setProfilingLevel(1, { slowms: 100 })

// æŸ¥çœ‹æ…¢æŸ¥è¯¢
db.system.profile.find().sort({ts: -1}).limit(5)
```

**ä¼˜åŒ–**:
```javascript
// åˆ›å»ºé€‚å½“çš„ç´¢å¼•
db.market_data_1d.createIndex(
  { "metadata.symbol": 1, "datetime": 1 }
)

// ä½¿ç”¨æŸ¥è¯¢è®¡åˆ’åˆ†æ
db.market_data_1d.find({...}).explain("executionStats")
```

### è°ƒè¯•æŠ€å·§

#### å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging

logging.basicConfig(level=logging.DEBUG)

# æˆ–é’ˆå¯¹ç‰¹å®šæ¨¡å—
logging.getLogger("cherryquant.data").setLevel(logging.DEBUG)
```

#### æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats

async def main():
    # your code here
    pass

# æ€§èƒ½åˆ†æ
cProfile.run('asyncio.run(main())', 'stats')

# æŸ¥çœ‹ç»Ÿè®¡
p = pstats.Stats('stats')
p.sort_stats('cumulative').print_stats(20)
```

---

## ğŸ” å®‰å…¨å»ºè®®

### 1. æ•æ„Ÿä¿¡æ¯ç®¡ç†

```bash
# âŒ ä¸è¦æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶
.env
*.env.local
secrets/

# âœ… ä½¿ç”¨ç¯å¢ƒå˜é‡
export TUSHARE_TOKEN="xxx"
export MONGODB_PASSWORD="xxx"
```

### 2. æ•°æ®åº“è®¿é—®æ§åˆ¶

```javascript
// åˆ›å»ºåªè¯»ç”¨æˆ·
use cherryquant_prod;

db.createUser({
  user: "readonly",
  pwd: "secure_password",
  roles: [{ role: "read", db: "cherryquant_prod" }]
})

// åˆ›å»ºè¯»å†™ç”¨æˆ·
db.createUser({
  user: "readwrite",
  pwd: "secure_password",
  roles: [{ role: "readWrite", db: "cherryquant_prod" }]
})
```

### 3. ç½‘ç»œéš”ç¦»

```yaml
# docker-compose.yml
services:
  mongodb:
    networks:
      - backend
    # ä¸æš´éœ²åˆ°å…¬ç½‘
    ports:
      - "127.0.0.1:27017:27017"

networks:
  backend:
    driver: bridge
```

### 4. å¤‡ä»½ç­–ç•¥

```bash
# æ¯æ—¥å¤‡ä»½
0 2 * * * mongodump --uri="mongodb://user:pass@localhost:27017/cherryquant_prod" --out=/backup/$(date +\%Y\%m\%d)

# ä¿ç•™æœ€è¿‘7å¤©çš„å¤‡ä»½
find /backup -type d -mtime +7 -exec rm -rf {} \;
```

---

## ğŸ“š å…¶ä»–èµ„æº

- [API æ–‡æ¡£](API_REFERENCE.md)
- [æ¶æ„è®¾è®¡](ARCHITECTURE.md)
- [ç”Ÿäº§å°±ç»ªçŠ¶æ€](PRODUCTION_READY_STATUS.md)
- [FAQ](FAQ.md)

---

## ğŸ†˜ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜ï¼Ÿ

1. æŸ¥çœ‹ [FAQ](FAQ.md)
2. æœç´¢ [Issues](https://github.com/your-org/CherryQuant/issues)
3. æäº¤æ–° [Issue](https://github.com/your-org/CherryQuant/issues/new)

---

**ç¥éƒ¨ç½²é¡ºåˆ©ï¼** ğŸ‰
