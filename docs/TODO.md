# CherryQuant Data Pipeline - TODO & Issues

**Last Updated**: 2024å¹´
**Status**: Alpha/Early Beta

æœ¬æ–‡æ¡£è®°å½•äº† CherryQuant æ•°æ®ç®¡é“çš„æ‰€æœ‰å·²çŸ¥é—®é¢˜ã€æ”¹è¿›å»ºè®®å’Œæœªæ¥è®¡åˆ’ã€‚

---

## âœ… å·²ä¿®å¤çš„å…³é”®é—®é¢˜ (Fixed Critical Issues)

### 1. Type Annotation Errors âœ…
**Status**: FIXED
**Impact**: Runtime errors
**Files Modified**:
- `/src/cherryquant/data/cleaners/validator.py`
- `/src/cherryquant/data/cleaners/normalizer.py`

**Changes**:
- Added `Any` to imports: `from typing import List, Dict, Optional, Tuple, Any`
- Fixed `value: Optional[any]` â†’ `value: Optional[Any]`
- Fixed `price: any` â†’ `price: Any`

---

### 2. Missing `is_main_contract` Field âœ…
**Status**: FIXED
**Impact**: Runtime errors in contract queries
**Files Modified**:
- `/src/cherryquant/data/collectors/base_collector.py`
- `/src/cherryquant/data/storage/metadata_repository.py`

**Changes**:
- Added `is_main_contract: bool = False` field to `ContractInfo` dataclass
- Updated `to_dict()` method to include `is_main_contract`
- Updated `_document_to_contract()` to handle `is_main_contract` field

---

### 3. Field Name Inconsistencies (pre_trading_date) âœ…
**Status**: FIXED
**Impact**: Data corruption and query failures
**File Modified**: `/src/cherryquant/data/storage/metadata_repository.py`

**Changes**:
- Standardized on `pre_trading_date` (was mixing `pre_trading_date` and `prev_trading_date`)
- Updated all database field names from `prev_trading_date` to `pre_trading_date`
- Lines changed: 422, 432, 569, 570, 621

---

### 4. Property vs Field Issue (is_active) âœ…
**Status**: FIXED
**Impact**: Data persistence inconsistency
**File Modified**: `/src/cherryquant/data/storage/metadata_repository.py`

**Changes**:
- Removed `is_active` from database storage (it's a computed property)
- Added two-stage filtering: database query + code-level filtering for `is_active`
- Updated `query_contracts()` to filter `is_active` in Python after fetching from DB

**Reasoning**: `is_active` is dynamically computed from `expire_date`, so storing it in DB creates inconsistency.

---

### 5. Null Check for Symbol âœ…
**Status**: FIXED
**Impact**: Potential crashes when symbol is None
**File Modified**: `/src/cherryquant/data/storage/timeseries_repository.py`

**Changes**:
- Line 250: Added null check: `data.symbol.rstrip("0123456789") if data.symbol else ""`

---

## ğŸ”´ æœªä¿®å¤çš„å…³é”®é—®é¢˜ (Remaining Critical Issues)

ç›®å‰æ‰€æœ‰å…³é”®é—®é¢˜å·²ä¿®å¤ã€‚ç³»ç»Ÿå¯ä»¥æ­£å¸¸è¿è¡Œï¼Œä½†ä»æœ‰ä¸­ç­‰ä¼˜å…ˆçº§å’Œæ¬¡è¦é—®é¢˜éœ€è¦å¤„ç†ã€‚

---

## ğŸŸ¡ ä¸­ç­‰ä¼˜å…ˆçº§é—®é¢˜ (Medium Priority Issues)

### 1. Inconsistent Error Handling
**Location**: Multiple files
**Impact**: Debugging difficulties
**Issue**: Errors are logged and re-raised without context

**Example** (`tushare_collector.py:314-316`):
```python
except Exception as e:
    logger.error(f"âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
    raise  # No context added
```

**Fix Needed**:
```python
except Exception as e:
    logger.error(f"âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥: {e}")
    raise DataCollectionError(f"Failed to fetch {symbol}") from e
```

**Estimated Effort**: 4-6 hours
**Priority**: Medium

---

### 2. Potential Race Condition in Cache Strategy
**Location**: `cache_strategy.py:142-149`
**Impact**: Cache corruption in multi-threaded environments
**Issue**: No locking mechanism for L1 cache operations

**Current Code**:
```python
if len(self._l1_cache) >= self.l1_max_size:
    if self._l1_access_order:
        lru_key = self._l1_access_order.pop(0)  # Not thread-safe
        if lru_key in self._l1_cache:
            del self._l1_cache[lru_key]
```

**Fix Options**:
1. Add `threading.Lock()` for L1 operations
2. Use `threading.local()` for per-thread caches
3. Document that cache is single-threaded only

**Estimated Effort**: 3-4 hours
**Priority**: Medium-High

---

### 3. Hardcoded Magic Numbers
**Location**: Multiple files
**Impact**: Maintainability

**Examples**:
- `quality_control.py:279`: `if len(trading_days) < expected_days * 0.5:`
- `contract_service.py:325`: `if len(contracts) < 10:`
- `normalizer.py:212`: Conflicting "1m" mapping

**Fix Needed**: Extract to module-level or class-level constants:
```python
# quality_control.py
QUALITY_COMPLETENESS_THRESHOLD = 0.5  # 50% minimum data completeness

# contract_service.py
MIN_CONTRACTS_FOR_MAIN_CONTRACT = 10

# normalizer.py
# Remove ambiguous "1m" mapping, use "1M" for month
```

**Estimated Effort**: 2-3 hours
**Priority**: Medium

---

### 4. Type Hints Incomplete
**Location**: Multiple files
**Impact**: IDE support and type checking

**Issues**:
- `cache_strategy.py:84`: Uses `dict[str, tuple]` instead of `Dict[str, Tuple]` (Python < 3.9 incompatible)
- Missing return type hints in some methods
- `Callable` without full signature

**Fix Needed**:
```python
# Before
self._l1_cache: dict[str, tuple[Any, datetime]] = {}

# After (Python 3.7+ compatible)
self._l1_cache: Dict[str, Tuple[Any, datetime]] = {}
```

**Estimated Effort**: 4-5 hours
**Priority**: Medium

---

### 5. Direct Access to Private Attributes
**Location**: `pipeline.py:122-124`
**Impact**: Encapsulation violation

**Current Code**:
```python
if not self.db_manager._is_connected:  # Accessing private attribute
    await self.db_manager.connect()
```

**Fix Needed**:
```python
if not self.db_manager.is_connected:  # Use public property
    await self.db_manager.connect()
```

**Estimated Effort**: 1 hour
**Priority**: Low-Medium

---

### 6. Potential Memory Leak in Batch Operations
**Location**: `batch_query.py:120-123`
**Impact**: Memory exhaustion for large batches

**Issue**: All results held in memory simultaneously

**Fix Needed**: Implement chunking/streaming for large batches:
```python
async def execute_batch_streaming(self, requests, chunk_size=100):
    for i in range(0, len(requests), chunk_size):
        chunk = requests[i:i+chunk_size]
        yield await self.execute_batch(chunk)
```

**Estimated Effort**: 6-8 hours
**Priority**: Medium (only for large-scale use)

---

## ğŸŸ¢ æ¬¡è¦é—®é¢˜ (Minor Issues)

### 1. Inconsistent Logging Style
**Impact**: Log aggregation compatibility
**Issue**: Mix of emoji logs and plain text

**Fix**: Standardize to plain text or make emojis optional:
```python
# Add to config
USE_EMOJI_LOGS = os.getenv("USE_EMOJI_LOGS", "false").lower() == "true"

# In code
if USE_EMOJI_LOGS:
    logger.info("âœ… ä¿å­˜æˆåŠŸ")
else:
    logger.info("[SUCCESS] ä¿å­˜æˆåŠŸ")
```

**Estimated Effort**: 3-4 hours
**Priority**: Low

---

### 2. Redundant Dictionary Access
**Location**: `metadata_repository.py:240-242`
**Impact**: Minor performance

**Current Code**:
```python
if self.enable_cache and cache_key in self._contract_cache:
    return self._contract_cache[cache_key]  # Dictionary accessed twice
```

**Fix**:
```python
if self.enable_cache:
    cached = self._contract_cache.get(cache_key)
    if cached:
        return cached
```

**Estimated Effort**: 1 hour
**Priority**: Low

---

### 3. Missing Docstring Details
**Impact**: API documentation quality
**Issue**: Many methods missing:
- Exceptions raised
- Side effects
- Thread safety guarantees

**Example**:
```python
async def save_batch(self, data_list: List[MarketData]) -> int:
    """
    æ‰¹é‡ä¿å­˜æ•°æ®

    Args:
        data_list: æ•°æ®åˆ—è¡¨

    Returns:
        int: ä¿å­˜æˆåŠŸçš„æ•°é‡

    Raises:
        BulkWriteError: æ‰¹é‡å†™å…¥å¤±è´¥
        ConnectionError: æ•°æ®åº“è¿æ¥å¤±è´¥

    Side Effects:
        - ä¿®æ”¹æ•°æ®åº“
        - æ›´æ–°å†…éƒ¨ç»Ÿè®¡è®¡æ•°å™¨

    Thread Safety:
        çº¿ç¨‹å®‰å…¨ï¼Œä½¿ç”¨æ•°æ®åº“é”ä¿è¯åŸå­æ€§
    """
```

**Estimated Effort**: 8-10 hours
**Priority**: Low-Medium

---

### 4. Conflicting Mapping ("1m")
**Location**: `normalizer.py:212-213`
**Impact**: Ambiguity in timeframe parsing

**Current Code**:
```python
"1m": TimeFrame.MONTH_1,  # æ³¨æ„ï¼šä¸1åˆ†é’Ÿå†²çªï¼Œéœ€è¦ä¸Šä¸‹æ–‡åˆ¤æ–­
"1month": TimeFrame.MONTH_1,
```

**Fix**: Remove conflicting mapping:
```python
# For minutes, use lowercase 'm'
"1min": TimeFrame.MIN_1,
# For months, use uppercase 'M'
"1M": TimeFrame.MONTH_1,
"1month": TimeFrame.MONTH_1,
# Remove: "1m": TimeFrame.MONTH_1
```

**Estimated Effort**: 2 hours
**Priority**: Medium

---

### 5. Inefficient List Operations
**Location**: `cache_strategy.py:116`
**Impact**: O(n) performance

**Current Code**:
```python
if key in self._l1_access_order:
    self._l1_access_order.remove(key)  # O(n) operation
```

**Fix**: Use `collections.OrderedDict`:
```python
from collections import OrderedDict

class CacheStrategy:
    def __init__(self):
        self._l1_cache = OrderedDict()  # LRU built-in
```

**Estimated Effort**: 3-4 hours
**Priority**: Medium

---

## ğŸ“¦ ç¼ºå¤±çš„åŠŸèƒ½ (Missing Features)

### 1. Package-Level Exports
**Impact**: User convenience
**Issue**: Empty `__init__.py` files force deep imports

**Current**:
```python
from cherryquant.data.collectors.tushare_collector import TushareCollector
from cherryquant.data.pipeline import DataPipeline
```

**Desired**:
```python
from cherryquant.data import TushareCollector, DataPipeline
```

**Fix**: Add to `/src/cherryquant/data/__init__.py`:
```python
__all__ = [
    "DataPipeline",
    "TushareCollector",
    "QueryBuilder",
    "BatchQueryExecutor",
    "MarketData",
    "ContractInfo",
    "TradingDay",
]

from .pipeline import DataPipeline
from .collectors.tushare_collector import TushareCollector
from .query.query_builder import QueryBuilder
from .query.batch_query import BatchQueryExecutor
from .collectors.base_collector import MarketData, ContractInfo, TradingDay
```

**Estimated Effort**: 2 hours
**Priority**: Medium

---

### 2. Integration Tests
**Impact**: System reliability
**Issue**: No end-to-end tests

**Needed Tests**:
- Full pipeline: collect â†’ clean â†’ store â†’ query
- Error recovery scenarios
- Cache behavior verification
- Concurrent operations

**Estimated Effort**: 20-30 hours
**Priority**: High (before production)

---

### 3. Error Recovery Mechanisms
**Impact**: System resilience
**Issue**: No retry logic or rollback

**Needed**:
- Exponential backoff for API calls
- Transaction rollback for failed batches
- Dead letter queue for failed operations

**Estimated Effort**: 15-20 hours
**Priority**: High (before production)

---

### 4. Schema Migration Support
**Impact**: Database upgrades
**Issue**: No versioning or migration framework

**Needed**:
- Schema version tracking in DB
- Migration scripts
- Backward compatibility checks

**Estimated Effort**: 10-15 hours
**Priority**: Medium (for V1.0)

---

### 5. Monitoring and Alerting
**Impact**: Operational visibility
**Issue**: No hooks for metrics/alerts

**Needed**:
- Prometheus metrics exporter
- Custom callback hooks
- Health check endpoint

**Estimated Effort**: 12-16 hours
**Priority**: Medium (before production)

---

## ğŸ”§ é‡æ„å»ºè®® (Refactoring Suggestions)

### 1. Over-Abstraction in QueryBuilder
**Current**: 522 lines with complex two-stage filtering
**Issue**: Much filtering could be pushed to MongoDB aggregation

**Suggestion**: Use MongoDB aggregation pipeline:
```python
# Instead of fetching all and filtering in Python
data = await repo.query(...)
filtered = [d for d in data if d.volume > 10000]

# Use MongoDB $match
pipeline = [
    {"$match": {"metadata.symbol": "rb2501"}},
    {"$match": {"volume": {"$gt": 10000}}},
    {"$sort": {"datetime": 1}},
    {"$limit": 20}
]
data = await collection.aggregate(pipeline).to_list()
```

**Benefits**: 10-100x performance improvement for large datasets
**Estimated Effort**: 20-25 hours
**Priority**: Low (works fine for small-medium datasets)

---

### 2. Duplicate Code in Services
**Location**: `calendar_service.py`, `contract_service.py`
**Issue**: Near-identical patterns

**Suggestion**: Extract base service class:
```python
class BaseService:
    def __init__(self, repository, cache):
        self.repository = repository
        self.cache = cache

    async def _get_with_cache(self, cache_key, fetcher):
        # Common cache-first logic
        cached = await self.cache.get(cache_key)
        if cached:
            return cached
        result = await fetcher()
        await self.cache.set(cache_key, result)
        return result

class CalendarService(BaseService):
    async def get_trading_day(self, date, exchange):
        return await self._get_with_cache(
            f"trading_day:{date}",
            lambda: self.repository.get_trading_day(date, exchange)
        )
```

**Estimated Effort**: 8-10 hours
**Priority**: Medium

---

### 3. Centralized Validation Logic
**Location**: Multiple files
**Issue**: Duplicate validation code

**Suggestion**: Create validation utility module:
```python
# validation_utils.py
class SymbolValidator:
    @staticmethod
    def validate_symbol(symbol: str) -> str:
        # Centralized symbol validation
        if not symbol:
            raise ValueError("Symbol cannot be empty")
        return symbol.strip().upper()

    @staticmethod
    def validate_date_range(start: datetime, end: datetime):
        if start > end:
            raise ValueError("Start date must be before end date")
```

**Estimated Effort**: 6-8 hours
**Priority**: Medium

---

## ğŸ“‹ å¾…åŠäº‹é¡¹ä¼˜å…ˆçº§æ±‡æ€» (Priority Summary)

### ç«‹å³å¤„ç† (Immediate - Before Production)
âœ… ~~Type annotation errors~~ (DONE)
âœ… ~~Missing is_main_contract field~~ (DONE)
âœ… ~~Field name inconsistencies~~ (DONE)
âœ… ~~Null check in timeseries_repository~~ (DONE)
- [ ] Integration tests (20-30h)
- [ ] Error recovery mechanisms (15-20h)

**Total Estimated Effort**: 35-50 hours

---

### çŸ­æœŸ (Short Term - Before Beta)
- [ ] Race condition in cache (3-4h)
- [ ] Hardcoded magic numbers (2-3h)
- [ ] Type hints completion (4-5h)
- [ ] Conflicting "1m" mapping (2h)
- [ ] Package-level exports (2h)

**Total Estimated Effort**: 13-16 hours

---

### ä¸­æœŸ (Medium Term - For V1.0)
- [ ] QueryBuilder optimization (20-25h)
- [ ] Duplicate code extraction (8-10h)
- [ ] Centralized validation (6-8h)
- [ ] Schema migration support (10-15h)
- [ ] Monitoring and alerting (12-16h)

**Total Estimated Effort**: 56-74 hours

---

### é•¿æœŸ (Long Term - Nice to Have)
- [ ] Inconsistent error handling (4-6h)
- [ ] Logging standardization (3-4h)
- [ ] Docstring improvements (8-10h)
- [ ] Performance optimizations (varies)

**Total Estimated Effort**: 15-20+ hours

---

## ğŸ“Š ä»£ç è´¨é‡è¯„ä¼° (Code Quality Assessment)

| ç»´åº¦ | è¯„åˆ† | è¯´æ˜ |
|------|------|------|
| **æ¶æ„è®¾è®¡** | â­â­â­â­â­ | åˆ†å±‚æ¸…æ™°ï¼Œè®¾è®¡æ¨¡å¼è¿ç”¨å¾—å½“ |
| **ä»£ç å¯è¯»æ€§** | â­â­â­â­ | æ³¨é‡Šè¯¦å°½ï¼Œæ•™å­¦ä»·å€¼é«˜ |
| **ç±»å‹å®‰å…¨** | â­â­â­â­ | å·²ä¿®å¤ä¸»è¦é—®é¢˜ï¼Œä»æœ‰æ”¹è¿›ç©ºé—´ |
| **é”™è¯¯å¤„ç†** | â­â­â­ | åŸºæœ¬è¦†ç›–ï¼Œç¼ºå°‘æ¢å¤æœºåˆ¶ |
| **æ€§èƒ½** | â­â­â­â­ | 80-90% QuantBox æ€§èƒ½ |
| **æµ‹è¯•è¦†ç›–** | â­â­ | æœ‰å•å…ƒæµ‹è¯•ç¤ºä¾‹ï¼Œç¼ºé›†æˆæµ‹è¯• |
| **æ–‡æ¡£è´¨é‡** | â­â­â­â­â­ | æ–‡æ¡£è¯¦å°½ï¼Œç¤ºä¾‹å®Œæ•´ |
| **ç”Ÿäº§å°±ç»ª** | â­â­â­ | éœ€è¦è¡¥å……æµ‹è¯•å’Œé”™è¯¯å¤„ç† |

**æ€»ä½“è¯„åˆ†**: B+ (82/100)

---

## ğŸš€ å‘å¸ƒè·¯çº¿å›¾ (Release Roadmap)

### Alpha v0.1 (Current)
- âœ… Core functionality implemented
- âœ… Critical bugs fixed
- âœ… Documentation complete
- âš ï¸ Integration tests missing
- âš ï¸ Error recovery missing

### Beta v0.5 (Target: +35-50 hours)
- [ ] Integration tests complete
- [ ] Error recovery implemented
- [ ] Type hints fully consistent
- [ ] Package exports added
- [ ] Cache thread-safety ensured

### RC v0.9 (Target: +50-90 hours from Beta)
- [ ] QueryBuilder optimized
- [ ] Services refactored
- [ ] Schema migrations added
- [ ] Monitoring hooks added
- [ ] Performance tuned

### V1.0 (Production Ready)
- [ ] All medium priority issues resolved
- [ ] Complete test coverage (>80%)
- [ ] Production deployment guide
- [ ] Operational runbook
- [ ] Performance benchmarks published

---

## ğŸ“ è´¡çŒ®æŒ‡å— (Contribution Guide)

å¦‚æœä½ æƒ³å‚ä¸ä¿®å¤è¿™äº›é—®é¢˜ï¼š

1. **é€‰æ‹©ä»»åŠ¡**: ä» TODO åˆ—è¡¨é€‰æ‹©ä¸€ä¸ªä»»åŠ¡
2. **åˆ›å»ºåˆ†æ”¯**: `git checkout -b fix/issue-name`
3. **ç¼–å†™æµ‹è¯•**: å…ˆå†™æµ‹è¯•ï¼Œå†å†™å®ç°
4. **æäº¤ PR**: åŒ…å«æµ‹è¯•å’Œæ–‡æ¡£æ›´æ–°
5. **ä»£ç å®¡æŸ¥**: ç­‰å¾… review å’Œåˆå¹¶

**ä¼˜å…ˆçº§å»ºè®®**:
- æ–°æ‰‹ï¼šä»"æ¬¡è¦é—®é¢˜"å¼€å§‹
- ä¸­çº§ï¼šå¤„ç†"ä¸­ç­‰ä¼˜å…ˆçº§é—®é¢˜"
- é«˜çº§ï¼šè´Ÿè´£"é‡æ„å»ºè®®"å’Œ"ç¼ºå¤±åŠŸèƒ½"

---

## ğŸ“§ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·ï¼š
- æäº¤ GitHub Issue
- å‚åŠ è¯¾ç¨‹ç­”ç–‘
- å‘é€é‚®ä»¶è‡³é¡¹ç›®ç»´æŠ¤è€…

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2024å¹´
**ç»´æŠ¤è€…**: CherryQuant Team
