"""
PostgreSQL åˆ° MongoDB æ•°æ®è¿ç§»è„šæœ¬
ç”¨äºå°†ç°æœ‰ PostgreSQL (TimescaleDB) æ•°æ®è¿ç§»åˆ° MongoDB
"""
import asyncio
import logging
from datetime import datetime
from typing import Dict, Any, List
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

import asyncpg
from motor.motor_asyncio import AsyncIOMotorClient
from bson import Decimal128
from dotenv import load_dotenv
import os

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class DataMigrator:
    """æ•°æ®è¿ç§»å™¨"""

    def __init__(self):
        # PostgreSQL é…ç½®
        self.pg_config = {
            "host": os.getenv("POSTGRES_HOST", "localhost"),
            "port": int(os.getenv("POSTGRES_PORT", "5432")),
            "database": os.getenv("POSTGRES_DB", "cherryquant"),
            "user": os.getenv("POSTGRES_USER", "cherryquant"),
            "password": os.getenv("POSTGRES_PASSWORD", "cherryquant123"),
        }

        # MongoDB é…ç½®
        self.mongo_uri = os.getenv("MONGODB_URI", "mongodb://localhost:27017")
        self.mongo_db_name = os.getenv("MONGODB_DATABASE", "cherryquant")

        self.pg_pool = None
        self.mongo_client = None
        self.mongo_db = None

    async def connect(self):
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        try:
            # è¿æ¥ PostgreSQL
            self.pg_pool = await asyncpg.create_pool(**self.pg_config)
            logger.info(f"âœ… PostgreSQL è¿æ¥æˆåŠŸ: {self.pg_config['host']}")

            # è¿æ¥ MongoDB
            self.mongo_client = AsyncIOMotorClient(self.mongo_uri)
            self.mongo_db = self.mongo_client[self.mongo_db_name]

            # æµ‹è¯•è¿æ¥
            await self.mongo_db.command("ping")
            logger.info(f"âœ… MongoDB è¿æ¥æˆåŠŸ: {self.mongo_uri}")

        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    async def disconnect(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.pg_pool:
            await self.pg_pool.close()
            logger.info("âœ“ PostgreSQL è¿æ¥å·²å…³é—­")
        if self.mongo_client:
            self.mongo_client.close()
            logger.info("âœ“ MongoDB è¿æ¥å·²å…³é—­")

    async def migrate_market_data(self, batch_size: int = 1000, limit: int = None):
        """
        è¿ç§»å¸‚åœºæ•°æ®

        Args:
            batch_size: æ¯æ‰¹å¤„ç†çš„è®°å½•æ•°
            limit: æœ€å¤§è¿ç§»è®°å½•æ•°ï¼ˆNone è¡¨ç¤ºå…¨éƒ¨ï¼‰
        """
        logger.info("\n" + "=" * 60)
        logger.info("å¼€å§‹è¿ç§» market_data è¡¨")
        logger.info("=" * 60)

        try:
            # è·å–æ€»è®°å½•æ•°
            async with self.pg_pool.acquire() as conn:
                total_count = await conn.fetchval("SELECT COUNT(*) FROM market_data")
                logger.info(f"PostgreSQL æ€»è®°å½•æ•°: {total_count:,}")

            if limit:
                total_count = min(total_count, limit)

            # MongoDB é›†åˆ
            collection = self.mongo_db["market_data"]

            # åˆ†æ‰¹è¿ç§»
            migrated = 0
            offset = 0

            while migrated < total_count:
                async with self.pg_pool.acquire() as conn:
                    # æŸ¥è¯¢ä¸€æ‰¹æ•°æ®
                    query = f"""
                        SELECT time, symbol, exchange, timeframe,
                               open_price, high_price, low_price, close_price,
                               volume, open_interest, turnover, settlement_price
                        FROM market_data
                        ORDER BY time
                        LIMIT {batch_size} OFFSET {offset}
                    """
                    rows = await conn.fetch(query)

                if not rows:
                    break

                # è½¬æ¢ä¸º MongoDB æ–‡æ¡£
                documents = []
                for row in rows:
                    doc = {
                        "time": row["time"],
                        "metadata": {
                            "symbol": row["symbol"],
                            "exchange": row["exchange"],
                            "timeframe": row["timeframe"]
                        },
                        "open_price": Decimal128(str(row["open_price"])) if row["open_price"] else None,
                        "high_price": Decimal128(str(row["high_price"])) if row["high_price"] else None,
                        "low_price": Decimal128(str(row["low_price"])) if row["low_price"] else None,
                        "close_price": Decimal128(str(row["close_price"])) if row["close_price"] else None,
                        "volume": int(row["volume"]) if row["volume"] else None,
                        "open_interest": int(row["open_interest"]) if row["open_interest"] else None,
                        "turnover": Decimal128(str(row["turnover"])) if row["turnover"] else None,
                        "settlement_price": Decimal128(str(row["settlement_price"])) if row["settlement_price"] else None,
                        "created_at": datetime.now()
                    }
                    documents.append(doc)

                # æ‰¹é‡æ’å…¥ MongoDBï¼ˆä½¿ç”¨ update_one + upsert é¿å…é‡å¤ï¼‰
                if documents:
                    from pymongo import UpdateOne
                    operations = [
                        UpdateOne(
                            {
                                "time": doc["time"],
                                "metadata.symbol": doc["metadata"]["symbol"],
                                "metadata.exchange": doc["metadata"]["exchange"],
                                "metadata.timeframe": doc["metadata"]["timeframe"]
                            },
                            {"$set": doc},
                            upsert=True
                        )
                        for doc in documents
                    ]
                    result = await collection.bulk_write(operations, ordered=False)
                    migrated += len(documents)
                    offset += batch_size

                    logger.info(f"  å·²è¿ç§»: {migrated:,} / {total_count:,} ({migrated/total_count*100:.1f}%)")

            logger.info(f"âœ… market_data è¿ç§»å®Œæˆ: {migrated:,} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"âŒ market_data è¿ç§»å¤±è´¥: {e}")
            raise

    async def migrate_trades(self):
        """è¿ç§»äº¤æ˜“è®°å½•"""
        logger.info("\n" + "=" * 60)
        logger.info("å¼€å§‹è¿ç§» trades è¡¨")
        logger.info("=" * 60)

        try:
            async with self.pg_pool.acquire() as conn:
                rows = await conn.fetch("SELECT * FROM trades ORDER BY entry_time")

            if not rows:
                logger.info("  trades è¡¨æ— æ•°æ®ï¼Œè·³è¿‡")
                return

            collection = self.mongo_db["trades"]
            documents = []

            for row in rows:
                doc = {
                    "symbol": row["symbol"],
                    "exchange": row["exchange"],
                    "direction": row["direction"],
                    "quantity": row["quantity"],
                    "entry_price": Decimal128(str(row["entry_price"])) if row.get("entry_price") else None,
                    "exit_price": Decimal128(str(row["exit_price"])) if row.get("exit_price") else None,
                    "entry_time": row["entry_time"],
                    "exit_time": row.get("exit_time"),
                    "entry_fee": Decimal128(str(row["entry_fee"])) if row.get("entry_fee") else None,
                    "exit_fee": Decimal128(str(row["exit_fee"])) if row.get("exit_fee") else None,
                    "gross_pnl": Decimal128(str(row["gross_pnl"])) if row.get("gross_pnl") else None,
                    "net_pnl": Decimal128(str(row["net_pnl"])) if row.get("net_pnl") else None,
                    "pnl_percentage": Decimal128(str(row["pnl_percentage"])) if row.get("pnl_percentage") else None,
                    "ai_decision_id": str(row["ai_decision_id"]) if row.get("ai_decision_id") else None,
                    "created_at": row.get("created_at", datetime.now()),
                    "updated_at": row.get("updated_at", datetime.now())
                }
                documents.append(doc)

            if documents:
                await collection.insert_many(documents)
                logger.info(f"âœ… trades è¿ç§»å®Œæˆ: {len(documents)} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"âŒ trades è¿ç§»å¤±è´¥: {e}")

    async def migrate_ai_decisions(self):
        """è¿ç§» AI å†³ç­–è®°å½•"""
        logger.info("\n" + "=" * 60)
        logger.info("å¼€å§‹è¿ç§» ai_decisions è¡¨")
        logger.info("=" * 60)

        try:
            async with self.pg_pool.acquire() as conn:
                rows = await conn.fetch("SELECT * FROM ai_decisions ORDER BY decision_time")

            if not rows:
                logger.info("  ai_decisions è¡¨æ— æ•°æ®ï¼Œè·³è¿‡")
                return

            collection = self.mongo_db["ai_decisions"]
            documents = []

            for row in rows:
                doc = {
                    "decision_time": row["decision_time"],
                    "symbol": row["symbol"],
                    "exchange": row["exchange"],
                    "action": row.get("action"),
                    "quantity": row.get("quantity"),
                    "leverage": row.get("leverage"),
                    "entry_price": Decimal128(str(row["entry_price"])) if row.get("entry_price") else None,
                    "profit_target": Decimal128(str(row["profit_target"])) if row.get("profit_target") else None,
                    "stop_loss": Decimal128(str(row["stop_loss"])) if row.get("stop_loss") else None,
                    "confidence": Decimal128(str(row["confidence"])) if row.get("confidence") else None,
                    "opportunity_score": row.get("opportunity_score"),
                    "selection_rationale": row.get("selection_rationale"),
                    "technical_analysis": row.get("technical_analysis"),
                    "risk_factors": row.get("risk_factors"),
                    "market_regime": row.get("market_regime"),
                    "volatility_index": row.get("volatility_index"),
                    "status": row.get("status", "pending"),
                    "executed_at": row.get("executed_at"),
                    "execution_price": Decimal128(str(row["execution_price"])) if row.get("execution_price") else None,
                    "created_at": row.get("created_at", datetime.now())
                }
                documents.append(doc)

            if documents:
                await collection.insert_many(documents)
                logger.info(f"âœ… ai_decisions è¿ç§»å®Œæˆ: {len(documents)} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"âŒ ai_decisions è¿ç§»å¤±è´¥: {e}")

    async def migrate_futures_contracts(self):
        """è¿ç§»æœŸè´§åˆçº¦ä¿¡æ¯"""
        logger.info("\n" + "=" * 60)
        logger.info("å¼€å§‹è¿ç§» futures_contracts è¡¨")
        logger.info("=" * 60)

        try:
            async with self.pg_pool.acquire() as conn:
                rows = await conn.fetch("SELECT * FROM futures_contracts")

            if not rows:
                logger.info("  futures_contracts è¡¨æ— æ•°æ®ï¼Œè·³è¿‡")
                return

            collection = self.mongo_db["futures_contracts"]
            documents = []

            for row in rows:
                doc = {
                    "symbol": row["symbol"],
                    "exchange": row["exchange"],
                    "name": row.get("name"),
                    "contract_size": row.get("contract_size"),
                    "margin_rate": Decimal128(str(row["margin_rate"])) if row.get("margin_rate") else None,
                    "price_tick": Decimal128(str(row["price_tick"])) if row.get("price_tick") else None,
                    "trading_unit": row.get("trading_unit"),
                    "created_at": row.get("created_at", datetime.now()),
                    "updated_at": row.get("updated_at", datetime.now())
                }
                documents.append(doc)

            if documents:
                from pymongo import UpdateOne
                operations = [
                    UpdateOne(
                        {"symbol": doc["symbol"], "exchange": doc["exchange"]},
                        {"$set": doc},
                        upsert=True
                    )
                    for doc in documents
                ]
                result = await collection.bulk_write(operations)
                logger.info(f"âœ… futures_contracts è¿ç§»å®Œæˆ: {len(documents)} æ¡è®°å½•")

        except Exception as e:
            logger.error(f"âŒ futures_contracts è¿ç§»å¤±è´¥: {e}")

    async def verify_migration(self):
        """éªŒè¯è¿ç§»ç»“æœ"""
        logger.info("\n" + "=" * 60)
        logger.info("éªŒè¯è¿ç§»ç»“æœ")
        logger.info("=" * 60)

        tables = ["market_data", "ai_decisions", "trades", "futures_contracts"]

        for table in tables:
            try:
                # PostgreSQL è®¡æ•°
                async with self.pg_pool.acquire() as conn:
                    pg_count = await conn.fetchval(f"SELECT COUNT(*) FROM {table}")

                # MongoDB è®¡æ•°
                collection = self.mongo_db[table]
                mongo_count = await collection.count_documents({})

                status = "âœ…" if pg_count == mongo_count else "âš ï¸ "
                logger.info(f"  {status} {table}: PG={pg_count:,}, Mongo={mongo_count:,}")

            except Exception as e:
                logger.error(f"  âŒ {table} éªŒè¯å¤±è´¥: {e}")

    async def run_full_migration(self, market_data_limit: int = None):
        """
        è¿è¡Œå®Œæ•´è¿ç§»æµç¨‹

        Args:
            market_data_limit: å¸‚åœºæ•°æ®æœ€å¤§è¿ç§»æ¡æ•°ï¼ˆNone = å…¨éƒ¨ï¼‰
        """
        try:
            await self.connect()

            # è¿ç§»å„ä¸ªè¡¨
            await self.migrate_futures_contracts()  # å…ˆè¿ç§»åˆçº¦ä¿¡æ¯ï¼ˆå°è¡¨ï¼‰
            await self.migrate_ai_decisions()  # AI å†³ç­–
            await self.migrate_trades()  # äº¤æ˜“è®°å½•
            await self.migrate_market_data(limit=market_data_limit)  # å¸‚åœºæ•°æ®ï¼ˆå¤§è¡¨ï¼‰

            # éªŒè¯
            await self.verify_migration()

            logger.info("\n" + "="*60)
            logger.info("ğŸ‰ æ•°æ®è¿ç§»å®Œæˆï¼")
            logger.info("="*60)

        except Exception as e:
            logger.error(f"\nâŒ è¿ç§»è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            raise
        finally:
            await self.disconnect()


async def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="PostgreSQL åˆ° MongoDB æ•°æ®è¿ç§»")
    parser.add_argument("--limit", type=int, default=None, help="é™åˆ¶ market_data è¿ç§»æ¡æ•°ï¼ˆæµ‹è¯•ç”¨ï¼‰")
    parser.add_argument("--verify-only", action="store_true", help="ä»…éªŒè¯ï¼Œä¸è¿ç§»")

    args = parser.parse_args()

    migrator = DataMigrator()

    if args.verify_only:
        await migrator.connect()
        await migrator.verify_migration()
        await migrator.disconnect()
    else:
        await migrator.run_full_migration(market_data_limit=args.limit)


if __name__ == "__main__":
    asyncio.run(main())
