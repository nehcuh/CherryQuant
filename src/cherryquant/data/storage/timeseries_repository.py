"""
æ—¶é—´åºåˆ—æ•°æ®ä»“å‚¨

æä¾› MongoDB æ—¶é—´åºåˆ—æ•°æ®çš„å­˜å‚¨å’ŒæŸ¥è¯¢åŠŸèƒ½ã€‚

æ•™å­¦è¦ç‚¹ï¼š
1. Repository æ¨¡å¼çš„åº”ç”¨
2. å¼‚æ­¥æ•°æ®åº“æ“ä½œ
3. æ‰¹é‡æ“ä½œä¼˜åŒ–
4. ç´¢å¼•å’ŒæŸ¥è¯¢ä¼˜åŒ–
"""

import logging
from typing import Any
from datetime import datetime
from decimal import Decimal

from motor.motor_asyncio import AsyncIOMotorDatabase, AsyncIOMotorCollection
from pymongo import IndexModel, ASCENDING, DESCENDING
from pymongo.errors import BulkWriteError

from cherryquant.data.collectors.base_collector import MarketData, Exchange, TimeFrame
from cherryquant.adapters.data_storage.mongodb_manager import MongoDBConnectionManager
from cherryquant.data.utils import retry_async, RetryConfig, RetryStrategy

logger = logging.getLogger(__name__)


class TimeSeriesRepository:
    """
    æ—¶é—´åºåˆ—æ•°æ®ä»“å‚¨

    è´Ÿè´£å¸‚åœºæ•°æ®ï¼ˆOHLCVï¼‰çš„æŒä¹…åŒ–å­˜å‚¨å’ŒæŸ¥è¯¢ã€‚
    ä½¿ç”¨ MongoDB æ—¶é—´åºåˆ—é›†åˆä¼˜åŒ–å­˜å‚¨å’ŒæŸ¥è¯¢æ€§èƒ½ã€‚

    æ•™å­¦è¦ç‚¹ï¼š
    1. Repository æ¨¡å¼éš”ç¦»æ•°æ®è®¿é—®é€»è¾‘
    2. æ—¶é—´åºåˆ—æ•°æ®çš„ç‰¹æ®Šå¤„ç†
    3. æ‰¹é‡æ“ä½œæå‡æ€§èƒ½
    4. ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢æ•ˆç‡
    """

    # é›†åˆåç§°æ˜ å°„
    COLLECTION_NAMES = {
        TimeFrame.MIN_1: "market_data_1m",
        TimeFrame.MIN_5: "market_data_5m",
        TimeFrame.MIN_15: "market_data_15m",
        TimeFrame.MIN_30: "market_data_30m",
        TimeFrame.HOUR_1: "market_data_1h",
        TimeFrame.DAY_1: "market_data_1d",
    }

    def __init__(
        self,
        connection_manager: MongoDBConnectionManager,
        enable_auto_index: bool = True,
    ):
        """
        åˆå§‹åŒ–æ—¶é—´åºåˆ—ä»“å‚¨

        Args:
            connection_manager: MongoDB è¿æ¥ç®¡ç†å™¨
            enable_auto_index: æ˜¯å¦è‡ªåŠ¨åˆ›å»ºç´¢å¼•

        æ•™å­¦è¦ç‚¹ï¼š
        1. ä¾èµ–æ³¨å…¥æ¨¡å¼
        2. é…ç½®å‚æ•°åŒ–
        """
        self.connection_manager = connection_manager
        self.enable_auto_index = enable_auto_index

        # é›†åˆç¼“å­˜
        self._collections: dict[str, AsyncIOMotorCollection] = {}
        self._indexes_created = set()

    @property
    def database(self) -> AsyncIOMotorDatabase:
        """è·å–æ•°æ®åº“å®ä¾‹"""
        if not self.connection_manager._async_db:
            raise RuntimeError("æ•°æ®åº“æœªè¿æ¥ï¼Œè¯·å…ˆè°ƒç”¨ connection_manager.connect()")
        return self.connection_manager._async_db

    def _get_collection(self, timeframe: TimeFrame) -> AsyncIOMotorCollection:
        """
        è·å–æŒ‡å®šæ—¶é—´å‘¨æœŸçš„é›†åˆ

        æ•™å­¦è¦ç‚¹ï¼š
        1. é›†åˆåˆ†ç¦»ç­–ç•¥ï¼ˆæŒ‰æ—¶é—´å‘¨æœŸï¼‰
        2. é›†åˆç¼“å­˜ä¼˜åŒ–
        """
        collection_name = self.COLLECTION_NAMES.get(timeframe)
        if not collection_name:
            raise ValueError(f"ä¸æ”¯æŒçš„æ—¶é—´å‘¨æœŸ: {timeframe}")

        # ä»ç¼“å­˜è·å–
        if collection_name not in self._collections:
            self._collections[collection_name] = self.database[collection_name]

        return self._collections[collection_name]

    async def ensure_indexes(self, timeframe: TimeFrame) -> None:
        """
        ç¡®ä¿ç´¢å¼•å·²åˆ›å»º

        æ•™å­¦è¦ç‚¹ï¼š
        1. ç´¢å¼•å¯¹æŸ¥è¯¢æ€§èƒ½çš„å½±å“
        2. å¤åˆç´¢å¼•çš„è®¾è®¡
        3. ç´¢å¼•åˆ›å»ºçš„å¹‚ç­‰æ€§
        """
        collection_name = self.COLLECTION_NAMES.get(timeframe)
        if not collection_name or collection_name in self._indexes_created:
            return

        collection = self._get_collection(timeframe)

        # å®šä¹‰ç´¢å¼•
        indexes = [
            IndexModel(
                [
                    ("metadata.symbol", ASCENDING),
                    ("metadata.exchange", ASCENDING),
                    ("datetime", ASCENDING),
                ],
                name="symbol_exchange_datetime",
            ),
            IndexModel(
                [("datetime", ASCENDING)],
                name="datetime",
            ),
            IndexModel(
                [
                    ("metadata.underlying", ASCENDING),
                    ("datetime", ASCENDING),
                ],
                name="underlying_datetime",
            ),
        ]

        try:
            await collection.create_indexes(indexes)
            self._indexes_created.add(collection_name)
            logger.info(f"âœ… ç´¢å¼•åˆ›å»ºæˆåŠŸ: {collection_name}")
        except Exception as e:
            logger.warning(f"âš ï¸ ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")

    async def save(self, data: MarketData) -> bool:
        """
        ä¿å­˜å•æ¡å¸‚åœºæ•°æ®

        Args:
            data: å¸‚åœºæ•°æ®

        Returns:
            bool: æ˜¯å¦ä¿å­˜æˆåŠŸ

        æ•™å­¦è¦ç‚¹ï¼š
        1. å•æ¡æ’å…¥ vs æ‰¹é‡æ’å…¥
        2. æ•°æ®è½¬æ¢ï¼ˆMarketData â†’ MongoDB æ–‡æ¡£ï¼‰
        3. é”™è¯¯å¤„ç†
        """
        return await self.save_batch([data]) > 0

    @retry_async(RetryConfig(
        max_attempts=2,
        base_delay=0.5,
        strategy=RetryStrategy.EXPONENTIAL,
        non_retriable_exceptions=(
            ValueError,
            TypeError,
            BulkWriteError,  # æ‰¹é‡å†™å…¥é”™è¯¯ï¼ˆå¦‚é‡å¤æ•°æ®ï¼‰ä¸é‡è¯•
        ),
    ))
    async def save_batch(
        self,
        data_list: list[MarketData],
        ordered: bool = False,
    ) -> int:
        """
        æ‰¹é‡ä¿å­˜å¸‚åœºæ•°æ®

        Args:
            data_list: æ•°æ®åˆ—è¡¨
            ordered: æ˜¯å¦æœ‰åºæ’å…¥ï¼ˆTrue: é‡åˆ°é”™è¯¯åœæ­¢ï¼ŒFalse: è·³è¿‡é”™è¯¯ç»§ç»­ï¼‰

        Returns:
            int: æˆåŠŸä¿å­˜çš„æ•°æ®é‡

        æ•™å­¦è¦ç‚¹ï¼š
        1. æ‰¹é‡æ“ä½œçš„æ€§èƒ½ä¼˜åŠ¿
        2. æœ‰åº vs æ— åºæ’å…¥çš„æƒè¡¡
        3. éƒ¨åˆ†å¤±è´¥çš„å¤„ç†
        4. è‡ªåŠ¨é‡è¯•æœºåˆ¶ (æ–°å¢) - ç½‘ç»œé—®é¢˜è‡ªåŠ¨é‡è¯•
        """
        if not data_list:
            return 0

        # æŒ‰æ—¶é—´å‘¨æœŸåˆ†ç»„
        grouped_data: dict[TimeFrame, list[MarketData]] = {}
        for data in data_list:
            if data.timeframe not in grouped_data:
                grouped_data[data.timeframe] = []
            grouped_data[data.timeframe].append(data)

        total_inserted = 0

        # åˆ†ç»„æ’å…¥
        for timeframe, group_data in grouped_data.items():
            try:
                collection = self._get_collection(timeframe)

                # ç¡®ä¿ç´¢å¼•å­˜åœ¨
                if self.enable_auto_index:
                    await self.ensure_indexes(timeframe)

                # è½¬æ¢ä¸ºæ–‡æ¡£
                documents = [self._to_document(data) for data in group_data]

                # æ‰¹é‡æ’å…¥
                result = await collection.insert_many(
                    documents,
                    ordered=ordered,
                )

                inserted_count = len(result.inserted_ids)
                total_inserted += inserted_count

                logger.info(
                    f"âœ… æ‰¹é‡ä¿å­˜æˆåŠŸ: {inserted_count}/{len(group_data)} æ¡ "
                    f"{timeframe.value} æ•°æ®"
                )

            except BulkWriteError as e:
                # å¤„ç†æ‰¹é‡å†™å…¥é”™è¯¯ï¼ˆå¦‚é‡å¤æ•°æ®ï¼‰
                inserted_count = e.details.get("nInserted", 0)
                total_inserted += inserted_count

                logger.warning(
                    f"âš ï¸ æ‰¹é‡ä¿å­˜éƒ¨åˆ†å¤±è´¥: {inserted_count}/{len(group_data)} æ¡æˆåŠŸ, "
                    f"{len(e.details.get('writeErrors', []))} æ¡å¤±è´¥"
                )

            except Exception as e:
                logger.error(f"âŒ æ‰¹é‡ä¿å­˜å¤±è´¥: {e}")

        return total_inserted

    def _to_document(self, data: MarketData) -> dict[str, Any]:
        """
        å°† MarketData è½¬æ¢ä¸º MongoDB æ–‡æ¡£

        æ•™å­¦è¦ç‚¹ï¼š
        1. æ•°æ®è½¬æ¢çš„å°è£…
        2. MongoDB æ–‡æ¡£ç»“æ„è®¾è®¡
        3. æ•°æ®ç±»å‹æ˜ å°„ï¼ˆDecimal â†’ floatï¼‰
        """
        return {
            "datetime": data.datetime,
            "metadata": {
                "symbol": data.symbol,
                "exchange": data.exchange.value,
                # æå–æ ‡çš„ä»£ç ï¼šå»é™¤åˆçº¦ä»£ç æœ«å°¾çš„æ•°å­—
                "underlying": data.symbol.rstrip("0123456789") if data.symbol else "",
            },
            "open": float(data.open),
            "high": float(data.high),
            "low": float(data.low),
            "close": float(data.close),
            "volume": data.volume,
            "open_interest": data.open_interest,
            "turnover": float(data.turnover) if data.turnover else None,
            "source": data.source.value,
            "collected_at": data.collected_at or datetime.now(),
        }

    def _from_document(self, doc: dict[str, Any], timeframe: TimeFrame) -> MarketData:
        """
        ä» MongoDB æ–‡æ¡£è½¬æ¢ä¸º MarketData

        æ•™å­¦è¦ç‚¹ï¼š
        1. åå‘è½¬æ¢
        2. æšä¸¾ç±»å‹çš„é‡å»º
        3. å¯é€‰å­—æ®µçš„å¤„ç†
        """
        from cherryquant.data.collectors.base_collector import DataSource

        metadata = doc.get("metadata", {})

        return MarketData(
            symbol=metadata.get("symbol"),
            exchange=Exchange(metadata.get("exchange")),  # Lookup by value
            datetime=doc.get("datetime"),
            timeframe=timeframe,
            open=Decimal(str(doc.get("open"))),
            high=Decimal(str(doc.get("high"))),
            low=Decimal(str(doc.get("low"))),
            close=Decimal(str(doc.get("close"))),
            volume=doc.get("volume"),
            open_interest=doc.get("open_interest"),
            turnover=Decimal(str(doc.get("turnover"))) if doc.get("turnover") else None,
            source=DataSource(doc.get("source", "custom")),  # Lookup by value, not name
            collected_at=doc.get("collected_at"),
        )

    @retry_async(RetryConfig(
        max_attempts=2,
        base_delay=0.3,
        strategy=RetryStrategy.EXPONENTIAL,
    ))
    async def query(
        self,
        symbol: str,
        exchange: Exchange,
        start_date: datetime,
        end_date: datetime,
        timeframe: TimeFrame = TimeFrame.DAY_1,
        limit: int | None = None,
    ) -> list[MarketData]:
        """
        æŸ¥è¯¢å¸‚åœºæ•°æ®

        Args:
            symbol: åˆçº¦ä»£ç 
            exchange: äº¤æ˜“æ‰€
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            timeframe: æ—¶é—´å‘¨æœŸ
            limit: æœ€å¤§è¿”å›æ•°é‡

        Returns:
            list[MarketData]: å¸‚åœºæ•°æ®åˆ—è¡¨

        æ•™å­¦è¦ç‚¹ï¼š
        1. æŸ¥è¯¢æ¡ä»¶æ„å»º
        2. ç´¢å¼•åˆ©ç”¨
        3. ç»“æœé›†é™åˆ¶
        4. æ’åºç­–ç•¥
        5. è‡ªåŠ¨é‡è¯•æœºåˆ¶ (æ–°å¢) - æŸ¥è¯¢å¤±è´¥è‡ªåŠ¨é‡è¯•
        """
        collection = self._get_collection(timeframe)

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        query = {
            "metadata.symbol": symbol,
            "metadata.exchange": exchange.value,
            "datetime": {
                "$gte": start_date,
                "$lte": end_date,
            },
        }

        # æ‰§è¡ŒæŸ¥è¯¢
        cursor = collection.find(query).sort("datetime", ASCENDING)

        if limit:
            cursor = cursor.limit(limit)

        # è½¬æ¢ç»“æœ
        documents = await cursor.to_list(length=None)
        result = [self._from_document(doc, timeframe) for doc in documents]

        logger.info(
            f"ğŸ“Š æŸ¥è¯¢å®Œæˆ: {len(result)} æ¡ {symbol}.{exchange.value} "
            f"{timeframe.value} æ•°æ®"
        )

        return result

    async def query_by_underlying(
        self,
        underlying: str,
        start_date: datetime,
        end_date: datetime,
        timeframe: TimeFrame = TimeFrame.DAY_1,
        exchange: Exchange | None = None,
    ) -> list[MarketData]:
        """
        æŒ‰æ ‡çš„ä»£ç æŸ¥è¯¢ï¼ˆå¦‚æŸ¥è¯¢æ‰€æœ‰ rb åˆçº¦ï¼‰

        æ•™å­¦è¦ç‚¹ï¼š
        1. é€šé…ç¬¦æŸ¥è¯¢
        2. å¯é€‰è¿‡æ»¤æ¡ä»¶
        """
        collection = self._get_collection(timeframe)

        query = {
            "metadata.underlying": underlying,
            "datetime": {
                "$gte": start_date,
                "$lte": end_date,
            },
        }

        if exchange:
            query["metadata.exchange"] = exchange.value

        cursor = collection.find(query).sort("datetime", ASCENDING)
        documents = await cursor.to_list(length=None)

        result = [self._from_document(doc, timeframe) for doc in documents]

        logger.info(
            f"ğŸ“Š æŸ¥è¯¢å®Œæˆ: {len(result)} æ¡ {underlying} "
            f"{timeframe.value} æ•°æ®"
        )

        return result

    async def get_latest(
        self,
        symbol: str,
        exchange: Exchange,
        timeframe: TimeFrame = TimeFrame.DAY_1,
    ) -> MarketData | None:
        """
        è·å–æœ€æ–°çš„ä¸€æ¡æ•°æ®

        æ•™å­¦è¦ç‚¹ï¼š
        1. æ’åºå’Œé™åˆ¶çš„ç»„åˆ
        2. å•æ–‡æ¡£æŸ¥è¯¢
        """
        collection = self._get_collection(timeframe)

        query = {
            "metadata.symbol": symbol,
            "metadata.exchange": exchange.value,
        }

        document = await collection.find_one(
            query,
            sort=[("datetime", DESCENDING)],
        )

        if document:
            return self._from_document(document, timeframe)

        return None

    async def count(
        self,
        symbol: str,
        exchange: Exchange,
        timeframe: TimeFrame = TimeFrame.DAY_1,
        start_date: datetime | None = None,
        end_date: datetime | None = None,
    ) -> int:
        """
        ç»Ÿè®¡æ•°æ®é‡

        æ•™å­¦è¦ç‚¹ï¼š
        1. count æ“ä½œçš„ä¼˜åŒ–
        2. å¯é€‰æ—¥æœŸèŒƒå›´
        """
        collection = self._get_collection(timeframe)

        query = {
            "metadata.symbol": symbol,
            "metadata.exchange": exchange.value,
        }

        if start_date or end_date:
            date_filter = {}
            if start_date:
                date_filter["$gte"] = start_date
            if end_date:
                date_filter["$lte"] = end_date
            query["datetime"] = date_filter

        count = await collection.count_documents(query)

        logger.debug(
            f"ğŸ“Š æ•°æ®ç»Ÿè®¡: {symbol}.{exchange.value} {timeframe.value} "
            f"å…± {count} æ¡"
        )

        return count

    async def delete_range(
        self,
        symbol: str,
        exchange: Exchange,
        start_date: datetime,
        end_date: datetime,
        timeframe: TimeFrame = TimeFrame.DAY_1,
    ) -> int:
        """
        åˆ é™¤æŒ‡å®šæ—¥æœŸèŒƒå›´çš„æ•°æ®

        æ•™å­¦è¦ç‚¹ï¼š
        1. æ‰¹é‡åˆ é™¤æ“ä½œ
        2. åˆ é™¤æ¡ä»¶çš„ç²¾ç¡®æ§åˆ¶
        """
        collection = self._get_collection(timeframe)

        query = {
            "metadata.symbol": symbol,
            "metadata.exchange": exchange.value,
            "datetime": {
                "$gte": start_date,
                "$lte": end_date,
            },
        }

        result = await collection.delete_many(query)
        deleted_count = result.deleted_count

        logger.info(
            f"ğŸ—‘ï¸ åˆ é™¤æ•°æ®: {deleted_count} æ¡ {symbol}.{exchange.value} "
            f"{timeframe.value} æ•°æ®"
        )

        return deleted_count

    async def get_date_range(
        self,
        symbol: str,
        exchange: Exchange,
        timeframe: TimeFrame = TimeFrame.DAY_1,
    ) -> tuple[datetime, datetime | None]:
        """
        è·å–æ•°æ®çš„æ—¥æœŸèŒƒå›´

        Returns:
            tuple: (æœ€æ—©æ—¥æœŸ, æœ€æ™šæ—¥æœŸ) æˆ– None

        æ•™å­¦è¦ç‚¹ï¼š
        1. èšåˆæŸ¥è¯¢
        2. min/max æ“ä½œ
        """
        collection = self._get_collection(timeframe)

        query = {
            "metadata.symbol": symbol,
            "metadata.exchange": exchange.value,
        }

        pipeline = [
            {"$match": query},
            {
                "$group": {
                    "_id": None,
                    "min_date": {"$min": "$datetime"},
                    "max_date": {"$max": "$datetime"},
                }
            },
        ]

        result = await collection.aggregate(pipeline).to_list(length=1)

        if result:
            return (result[0]["min_date"], result[0]["max_date"])

        return None

    async def upsert(self, data: MarketData) -> bool:
        """
        æ›´æ–°æˆ–æ’å…¥æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨åˆ™æ›´æ–°ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥ï¼‰

        æ•™å­¦è¦ç‚¹ï¼š
        1. upsert æ“ä½œ
        2. å”¯ä¸€æ€§çº¦æŸ
        """
        collection = self._get_collection(data.timeframe)

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶ï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
        filter_query = {
            "metadata.symbol": data.symbol,
            "metadata.exchange": data.exchange.value,
            "datetime": data.datetime,
        }

        # è½¬æ¢ä¸ºæ–‡æ¡£
        document = self._to_document(data)

        # æ‰§è¡Œ upsert
        result = await collection.replace_one(
            filter_query,
            document,
            upsert=True,
        )

        if result.upserted_id:
            logger.debug(f"âœ… æ’å…¥æ–°æ•°æ®: {data.symbol} @ {data.datetime}")
        elif result.modified_count > 0:
            logger.debug(f"âœ… æ›´æ–°æ•°æ®: {data.symbol} @ {data.datetime}")

        return True
